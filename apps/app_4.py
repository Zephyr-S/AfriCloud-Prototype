import streamlit as st
import pandas as pd
import os
import json
import hashlib
import mimetypes
import base64
import io
import time
import sqlite3
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import zipfile
import shutil
from pathlib import Path
import requests
from PIL import Image
import re
import numpy as np
from collections import Counter
import jieba
import jieba.analyse
import matplotlib.pyplot as plt
import seaborn as sns
import contextlib
from tools.generate_report import SmartAnalysisGenerator

try:
    import fitz  # PyMuPDF for PDF preview

    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False

# AIÂäüËÉΩÁõ∏ÂÖ≥Â∫ì
try:
    import openai

    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import easyocr

    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False

try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.cluster import KMeans
    from sklearn.naive_bayes import MultinomialNB
    from sklearn.pipeline import Pipeline

    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False

try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification

    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    # Â¶ÇÊûútransformers‰∏çÂèØÁî®ÔºåÊàë‰ª¨‰ΩøÁî®ÂÖ∂‰ªñÊñπÊ≥ï

# Set page config with premium aesthetics
st.set_page_config(
    page_title="Agribusiness Expert AI Cloud",
    page_icon="üåæ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Clean and modern CSS styling
st.markdown("""
<style>
    /* Overall Layout */
    .main {
        background: #f8fafc;
        color: #1e293b;
    }

    /* Title Styles */
    h1, h2, h3, h4, h5, h6 {
        color: #1e293b;
        font-family: 'Inter', 'Segoe UI', sans-serif;
        font-weight: 600;
        margin-bottom: 1rem;
    }

    /* Button Styles */
    .stButton>button {
        background: #3b82f6;
        color: white;
        border: none;
        padding: 8px 16px;
        border-radius: 8px;
        font-weight: 500;
        font-size: 14px;
        transition: all 0.2s ease;
        box-shadow: 0 2px 4px rgba(59, 130, 246, 0.2);
    }

    .stButton>button:hover {
        background: #2563eb;
        transform: translateY(-1px);
        box-shadow: 0 4px 8px rgba(59, 130, 246, 0.3);
    }

    /* File Card Styles */
    .file-card {
        background: white;
        border: 1px solid #e2e8f0;
        border-radius: 12px;
        padding: 16px;
        margin-bottom: 12px;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        transition: all 0.2s ease;
    }

    .file-card:hover {
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        transform: translateY(-1px);
    }

    /* Metric Card Styles */
    .metric-card {
        background: white;
        border: 1px solid #e2e8f0;
        border-radius: 8px;
        padding: 16px;
        text-align: center;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
    }

    /* Sidebar Styles */
    .css-1d391kg {
        background: white;
        border-right: 1px solid #e2e8f0;
    }

    /* Preview Section Styles */
    .preview-section {
        background: white;
        border: 1px solid #e2e8f0;
        border-radius: 8px;
        padding: 16px;
        margin-top: 16px;
    }

    /* File Icon Styles */
    .file-icon {
        font-size: 24px;
        margin-right: 12px;
    }

    /* Action Button Styles */
    .action-btn {
        background: #f1f5f9;
        border: 1px solid #e2e8f0;
        color: #64748b;
        padding: 6px 12px;
        border-radius: 6px;
        font-size: 12px;
        margin: 0 2px;
    }

    .action-btn:hover {
        background: #e2e8f0;
        color: #475569;
    }
</style>
""", unsafe_allow_html=True)


class CloudStorageManager:
    def __init__(self):
        # ‰∫ëÈÉ®ÁΩ≤ÈÖçÁΩÆ
        import os
        self.is_cloud_deployment = os.getenv('STREAMLIT_SERVER_PORT') is not None

        if self.is_cloud_deployment:
            # ‰∫ëÈÉ®ÁΩ≤Ôºö‰ΩøÁî®ÊåÅ‰πÖÂåñÂ≠òÂÇ®
            self.storage_dir = Path("/tmp/cloud_storage")
            self.cache_dir = Path("/tmp/local_cache")
            self.ai_analysis_dir = Path("/tmp/ai_analysis")
        else:
            # Êú¨Âú∞ÈÉ®ÁΩ≤Ôºö‰ΩøÁî®ÂΩìÂâçÁõÆÂΩï
            self.storage_dir = Path("cloud_storage")
            self.cache_dir = Path("local_cache")
            self.ai_analysis_dir = Path("ai_analysis")

        # ÂàõÂª∫ÁõÆÂΩï
        self.storage_dir.mkdir(exist_ok=True)
        self.cache_dir.mkdir(exist_ok=True)
        self.ai_analysis_dir.mkdir(exist_ok=True)

        self.db_path = self.storage_dir / "storage.db"
        self.init_database()

        # ÂàùÂßãÂåñAIÂäüËÉΩ
        self.init_ai_models()

        # Â§©Ê∞îÁºìÂ≠ò
        self.latest_weather: Optional[Dict[str, Any]] = None
        # ÈÅ•ÊÑüÁºìÂ≠ò
        self.latest_remote_sensing: Optional[Dict[str, Any]] = None

    def init_database(self):
        """ÂàùÂßãÂåñÊï∞ÊçÆÂ∫ì"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # Êñá‰ª∂Ë°®
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS files (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                filename TEXT NOT NULL,
                file_path TEXT NOT NULL,
                file_size INTEGER,
                file_type TEXT,
                folder_id INTEGER,
                upload_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                last_modified TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                checksum TEXT,
                is_cached BOOLEAN DEFAULT FALSE,
                FOREIGN KEY (folder_id) REFERENCES folders (id)
            )
        ''')

        # Êñá‰ª∂Â§πË°®
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS folders (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                folder_name TEXT NOT NULL,
                parent_folder_id INTEGER,
                created_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (parent_folder_id) REFERENCES folders (id)
            )
        ''')

        # ‰∏ä‰º†ËøõÂ∫¶Ë°®ÔºàÁî®‰∫éÊñ≠ÁÇπÁª≠‰º†Ôºâ
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS upload_progress (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                filename TEXT NOT NULL,
                total_size INTEGER,
                uploaded_size INTEGER,
                chunk_size INTEGER,
                checksum TEXT,
                upload_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        # AIÂàÜÊûêÁªìÊûúË°®
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS ai_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                file_id INTEGER,
                analysis_type TEXT,
                industry_category TEXT,
                extracted_text TEXT,
                key_phrases TEXT,
                summary TEXT,
                confidence_score REAL,
                method TEXT,
                analysis_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (file_id) REFERENCES files (id)
            )
        ''')

        # ËøÅÁßªÔºöËã•ÊóßË°®Êó† method ÂàóÂàôË°•ÂÖÖ
        try:
            cursor.execute("PRAGMA table_info(ai_analysis)")
            cols = [row[1] for row in cursor.fetchall()]
            if 'method' not in cols:
                cursor.execute('ALTER TABLE ai_analysis ADD COLUMN method TEXT')
        except Exception:
            pass

        # Ë°å‰∏öÂàÜÁ±ªË°®
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS industry_categories (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                category_name TEXT UNIQUE,
                keywords TEXT,
                description TEXT,
                created_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        conn.commit()
        conn.close()

    def init_ai_models(self):
        """ÂàùÂßãÂåñAIÊ®°Âûã"""
        # ÂàùÂßãÂåñË°å‰∏öÂàÜÁ±ªÂÖ≥ÈîÆËØçÔºàAgribusinessÁªÜÂàÜÔºåË°•ÂÖÖÈùûÊ¥≤Â∏∏ËßÅ‰ΩúÁâ©/Ë¶ÅÁ¥†Ôºâ
        self.industry_keywords = {
            "ÁßçÊ§ç‰∏ö": ["‰ΩúÁâ©", "ÁéâÁ±≥", "Â∞èÁ±≥", "È´òÁ≤±", "Ê∞¥Á®ª", "Êú®ËñØ", "Â±±ËçØ", "Á∫¢ËñØ", "Ëä±Áîü", "ËäùÈ∫ª", "ËëµËä±Á±Ω", "Ê£âËä±",
                       "ÂèØÂèØ", "ÂíñÂï°", "Ëå∂Âè∂", "È¶ôËïâ", "ËäíÊûú", "Ëè†Ëêù", "Ëî¨Ëèú", "ÊûúÂõ≠", "‰∫ßÈáè", "Âçï‰∫ß", "ÂÖ¨È°∑", "‰∫©",
                       "Êí≠Áßç", "Êî∂Ëé∑", "ÁÅåÊ∫â", "ÁóÖËô´ÂÆ≥", "Èô§Ëçâ", "ÂØÜÂ∫¶"],
            "ÁïúÁâß‰∏ö": ["ÁîüÁå™", "ÁâõÁæä", "ÂÆ∂Á¶Ω", "Â•∂Áâõ", "Âá∫Ê†è", "Â≠òÊ†è", "È•≤Êñô", "Êó•ÈæÑ", "Â¢ûÈáç", "ÊñôËÇâÊØî", "ÂÖçÁñ´", "ÂÖΩËçØ",
                       "Áñ´ÁóÖ", "ÁπÅËÇ≤", "ÁääÁâõ", "Â±†ÂÆ∞"],
            "ÂÜúËµÑ‰∏éÂúüÂ£§": ["ËÇ•Êñô", "Ê∞ÆËÇ•", "Á£∑ËÇ•", "ÈíæËÇ•", "ÈÖçÊñπÊñΩËÇ•", "ÊúâÊú∫Ë¥®", "pH", "ÂúüÂ£§ÁõêÂàÜ", "ÂæÆÈáèÂÖÉÁ¥†", "‰øùÊ∞¥",
                           "Ë¶ÜÁõñ", "Ê∑±Êùæ", "Áß∏ÁßÜËøòÁî∞"],
            "ÂÜú‰∏öÈáëËûç": ["ÈááË¥≠", "ÊàêÊú¨", "Ë¥∑Ê¨æ", "‰øùÂçï", "‰øùÈô©", "Ëµî‰ªò", "‰øùË¥π", "Êéà‰ø°", "Áé∞ÈáëÊµÅ", "Â∫îÊî∂", "Â∫î‰ªò",
                         "Âà©Ê∂¶", "ÊØõÂà©Áéá", "‰ª∑Ê†º", "ÊúüË¥ß"],
            "‰æõÂ∫îÈìæ‰∏é‰ªìÂÇ®": ["ÂÜ∑Èìæ", "‰ªìÂÇ®", "Áâ©ÊµÅ", "ËøêËæì", "Â∫ìÂÆπ", "ÊçüËÄó", "Âë®ËΩ¨", "‰∫§‰ªò", "ËÆ¢Âçï", "ÊâπÊ¨°", "ËøΩÊ∫Ø"],
            "Ê∞îÂÄô‰∏éÈÅ•ÊÑü": ["ÈôçÈõ®", "ÈôçÊ∞¥", "Ê∏©Â∫¶", "ÁßØÊ∏©", "Ëí∏Êï£", "Âπ≤Êó±", "NDVI", "EVI", "Âç´Êòü", "ÈÅ•ÊÑü", "Ê∞îË±°Á´ô",
                           "ËæêÂ∞Ñ", "Ê≤ôÊº†ËùóËô´", "ËçâÂú∞Ë¥™Â§úËõæ"],
            "ÂÜú‰∏öÁâ©ËÅîÁΩë": ["‰º†ÊÑüÂô®", "ÊπøÂ∫¶", "Âê´Ê∞¥Áéá", "EC", "ÈòàÂÄº", "ÈòÄÈó®", "Ê≥µÁ´ô", "Êª¥ÁÅå", "Âñ∑ÁÅå", "Ëá™Âä®Âåñ", "Êä•Ë≠¶"]
        }

        # ÂàùÂßãÂåñOCRÊ®°Âûã
        self.ocr_reader = None
        self.ocr_loading = False
        if OCR_AVAILABLE:
            try:
                # ÂºÇÊ≠•Âä†ËΩΩOCRÊ®°ÂûãÔºåÈÅøÂÖçÈòªÂ°ûÁïåÈù¢
                st.info("üîÑ Loading OCR model, please wait...")
                self.ocr_reader = easyocr.Reader(['ch_sim', 'en'])
                st.success("‚úÖ OCR model loaded successfully")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è OCR model loading failed: {str(e)}")
                st.info("üí° Please click 'üîÑ Reload AI' to retry later")

        # ÂàùÂßãÂåñÊñáÊú¨ÂàÜÁ±ªÊ®°Âûã
        self.text_classifier = None
        if TRANSFORMERS_AVAILABLE:
            try:
                # ‰ΩøÁî®‰∏≠ÊñáBERTÊ®°ÂûãËøõË°åÊñáÊú¨ÂàÜÁ±ª
                self.text_classifier = pipeline(
                    "text-classification",
                    model="bert-base-chinese",
                    tokenizer="bert-base-chinese"
                )
                st.success("‚úÖ BERT text classification model loaded successfully")
            except Exception as e:
                # Downgrade to info to avoid noisy toast; rules/ML will fallback
                st.info(f"BERT model loading failed, fallback will be used")
        else:
            st.info("‚ÑπÔ∏è Transformers library not installed, using machine learning classification")

        # ÂàùÂßãÂåñÊëòË¶ÅÁîüÊàêÊ®°Âûã
        self.summarizer = None
        if TRANSFORMERS_AVAILABLE:
            try:
                # ‰ΩøÁî®T5Ê®°ÂûãËøõË°åÊëòË¶ÅÁîüÊàê
                self.summarizer = pipeline(
                    "summarization",
                    model="t5-small",
                    tokenizer="t5-small"
                )
                st.success("‚úÖ T5 summarization model loaded successfully")
            except Exception as e:
                st.info("T5 summarization not available, using smart rules")
        else:
            st.info("‚ÑπÔ∏è Using smart summarization algorithm")

        # ÂàùÂßãÂåñÊú∫Âô®Â≠¶‰π†ÂàÜÁ±ªÂô®
        self.ml_classifier = None
        self.ml_trained = False
        if ML_AVAILABLE:
            try:
                # ‰ΩøÁî®Êú¥Á¥†Ë¥ùÂè∂ÊñØÂàÜÁ±ªÂô®
                self.ml_classifier = Pipeline([
                    ('tfidf', TfidfVectorizer(max_features=1000, stop_words=None)),
                    ('classifier', MultinomialNB())
                ])
                # Ëá™Âä®ÂàùÂßãÂåñÈ¢ÑËÆ≠ÁªÉÂàÜÁ±ªÂô®
                if self.init_pretrained_classifier():
                    st.success("‚úÖ Pre-trained machine learning classifier loaded successfully")
                else:
                    st.info("Pre-trained ML classifier unavailable, using keyword matching")
            except Exception as e:
                st.info("ML classifier init failed, using keyword matching")
        else:
            st.info("‚ÑπÔ∏è ‰ΩøÁî®ÂÖ≥ÈîÆËØçÂåπÈÖçÂàÜÁ±ª")

        # ÂàùÂßãÂåñÈªòËÆ§Ë°å‰∏öÂàÜÁ±ª
        self.init_default_categories()

    def fetch_weather_summary(self, latitude: float, longitude: float) -> Dict[str, Any]:
        """‰ªé Open-Meteo Ëé∑ÂèñÊú™Êù•7Â§©ÁöÑÊ∞îË±°ÊëòË¶ÅÔºàÊó†ÈúÄAPIÂØÜÈí•Ôºâ"""
        try:
            url = (
                "https://api.open-meteo.com/v1/forecast"
                f"?latitude={latitude}&longitude={longitude}"
                "&hourly=temperature_2m,precipitation"
                "&daily=precipitation_sum,temperature_2m_max,temperature_2m_min"
                "&forecast_days=7&timezone=auto"
            )
            resp = requests.get(url, timeout=10)
            resp.raise_for_status()
            data = resp.json()
            daily = data.get("daily", {})
            result = {
                "location": {"lat": latitude, "lon": longitude},
                "precipitation_sum": daily.get("precipitation_sum", []),
                "tmax": daily.get("temperature_2m_max", []),
                "tmin": daily.get("temperature_2m_min", []),
                "dates": daily.get("time", [])
            }
            # ÁÆÄË¶ÅÁªüËÆ°
            try:
                total_rain = float(sum(x for x in result["precipitation_sum"] if isinstance(x, (int, float))))
            except Exception:
                total_rain = 0.0
            result["summary"] = {
                "7d_total_rain_mm": round(total_rain, 1),
                "avg_tmax": round(sum(result["tmax"]) / max(1, len(result["tmax"])), 1) if result["tmax"] else None,
                "avg_tmin": round(sum(result["tmin"]) / max(1, len(result["tmin"])), 1) if result["tmin"] else None,
            }
            self.latest_weather = result
            return {"success": True, "weather": result}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def compute_remote_sensing_stub(self, latitude: float, longitude: float, days: int = 30) -> Dict[str, Any]:
        """ÈÅ•ÊÑüÊåáÊï∞Âç†‰ΩçÔºöÁîüÊàêËøëdaysÂ§©ÁöÑNDVI/EVIÁÆÄÊòìÊó∂Â∫èÔºàÊó†ÈúÄÂ§ñÈÉ®ÊúçÂä°Ôºâ„ÄÇ"""
        try:
            import math
            base_date = datetime.now()
            dates = [(base_date - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days - 1, -1, -1)]
            ndvi = []
            evi = []
            for i in range(days):
                # ÁîüÊàêÂπ≥ÊªëÁöÑÊ≥¢Âä®Êï∞ÊçÆÔºåËåÉÂõ¥ÂÅöÁâ©ÁêÜÂêàÁêÜÁ∫¶Êùü
                v = 0.5 + 0.3 * math.sin(i / 6.0) + 0.1 * math.sin(i / 2.5)
                ndvi.append(round(max(0.0, min(0.9, v)), 3))
                e = 0.4 + 0.25 * math.sin(i / 7.0 + 0.5)
                evi.append(round(max(0.0, min(0.8, e)), 3))
            summary = {
                "ndvi_avg": round(sum(ndvi) / len(ndvi), 3) if ndvi else None,
                "evi_avg": round(sum(evi) / len(evi), 3) if evi else None,
                "ndvi_last": ndvi[-1] if ndvi else None,
                "evi_last": evi[-1] if evi else None,
            }
            result = {
                "location": {"lat": latitude, "lon": longitude},
                "dates": dates,
                "ndvi": ndvi,
                "evi": evi,
                "summary": summary,
            }
            self.latest_remote_sensing = result
            return {"success": True, "remote_sensing": result}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def extract_agri_structured_fields(self, text: str) -> Dict[str, Any]:
        """ÂÜú‰∏öÊä•Ë°®Ê®°ÊùøÊäΩÂèñÔºàËßÑÂàôÁâàÂç†‰ΩçÔºâÔºö‰ΩúÁâ©„ÄÅÈù¢ÁßØ„ÄÅÊó•Êúü„ÄÅÊñΩËÇ•/ÁÅåÊ∫â/Áî®ËçØ/Âçï‰∫ßÁ≠â„ÄÇ"""
        if not text:
            return {}
        import re
        fields: Dict[str, Any] = {}
        try:
            # ‰ΩúÁâ©
            m = re.search(r'(‰ΩúÁâ©|ÂìÅÁßç|‰ΩúÁâ©ÂêçÁß∞)[Ôºö:Ôºå]\s*([\u4e00-\u9fffA-Za-z0-9]+)', text)
            if m: fields['‰ΩúÁâ©'] = m.group(2)
            # Èù¢ÁßØÔºà‰∫©/ÂÖ¨È°∑/haÔºâ
            m = re.search(r'(Èù¢ÁßØ|Êí≠ÁßçÈù¢ÁßØ|Êî∂Ëé∑Èù¢ÁßØ)[Ôºö:Ôºå]\s*([\d,.]+)\s*(‰∫©|ÂÖ¨È°∑|ha)', text)
            if m: fields['Èù¢ÁßØ'] = f"{m.group(2)} {m.group(3)}"
            # Êó•ÊúüÔºàÁÆÄÂçïËØÜÂà´ Âπ¥-Êúà-Êó• Êàñ Âπ¥/Êúà/Êó• Êàñ ‰∏≠ÊñáÔºâ
            m = re.search(r'(Êó•Êúü|Êó∂Èó¥|ËÆ∞ÂΩïÊó∂Èó¥)[Ôºö:Ôºå]\s*(\d{4}[-Âπ¥/]\d{1,2}[-Êúà/]\d{1,2})', text)
            if m: fields['Êó•Êúü'] = m.group(2)
            # ÊñΩËÇ•
            m = re.search(r'(ÊñΩËÇ•|ËÇ•Êñô|ÈÖçÊñπÊñΩËÇ•)[Ôºö:Ôºå]?\s*([\u4e00-\u9fffA-Za-z0-9]+)?\s*([\d,.]+)\s*(kg|ÂÖ¨Êñ§|Êñ§)', text)
            if m: fields['ÊñΩËÇ•'] = f"{(m.group(2) or '').strip()} {m.group(3)} {m.group(4)}".strip()
            # ÁÅåÊ∫â
            m = re.search(r'(ÁÅåÊ∫â|ÊµáÊ∞¥)[Ôºö:Ôºå]?\s*([\d,.]+)\s*(mm|Á´ãÊñπ|m3|Êñπ)', text)
            if m: fields['ÁÅåÊ∫â'] = f"{m.group(2)} {m.group(3)}"
            # Áî®ËçØ
            m = re.search(r'(ÂÜúËçØ|Áî®ËçØ|Èò≤Ê≤ª)[Ôºö:Ôºå]?\s*([\u4e00-\u9fffA-Za-z0-9]+)\s*([\d,.]+)\s*(ml|ÊØ´Âçá|L|Âçá|kg|ÂÖã|g)',
                          text)
            if m: fields['Áî®ËçØ'] = f"{m.group(2)} {m.group(3)} {m.group(4)}"
            # Âçï‰∫ß/‰∫ßÈáè
            m = re.search(r'(Âçï‰∫ß|‰∫©‰∫ß)[Ôºö:Ôºå]\s*([\d,.]+)\s*(Êñ§/‰∫©|ÂÖ¨Êñ§/‰∫©|kg/ha|t/ha)', text)
            if m: fields['Âçï‰∫ß'] = f"{m.group(2)} {m.group(3)}"
            m = re.search(r'(ÊÄª‰∫ß|‰∫ßÈáè)[Ôºö:Ôºå]\s*([\d,.]+)\s*(kg|Âê®|t)', text)
            if m: fields['‰∫ßÈáè'] = f"{m.group(2)} {m.group(3)}"
        except Exception:
            pass
        return fields

    def init_default_categories(self):
        """ÂàùÂßãÂåñÈªòËÆ§Ë°å‰∏öÂàÜÁ±ª"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        for category, keywords in self.industry_keywords.items():
            cursor.execute('''
                INSERT OR IGNORE INTO industry_categories (category_name, keywords, description)
                VALUES (?, ?, ?)
            ''', (category, json.dumps(keywords, ensure_ascii=False), f"{category}Áõ∏ÂÖ≥ÊñáÊ°£"))

        conn.commit()
        conn.close()

    def _to_english_category(self, category: str) -> str:
        mapping = {
            "ÁßçÊ§ç‰∏ö": "Planting",
            "ÁïúÁâß‰∏ö": "Livestock",
            "ÂÜúËµÑ‰∏éÂúüÂ£§": "Inputs-Soil",
            "ÂÜú‰∏öÈáëËûç": "Agri-Finance",
            "‰æõÂ∫îÈìæ‰∏é‰ªìÂÇ®": "SupplyChain-Storage",
            "Ê∞îÂÄô‰∏éÈÅ•ÊÑü": "Climate-RemoteSensing",
            "ÂÜú‰∏öÁâ©ËÅîÁΩë": "Agri-IoT",
        }
        return mapping.get(category, category)

    def generate_smart_report(self, file_id: int) -> Dict[str, Any]:
        """ÁîüÊàêÊô∫ËÉΩÊä•ÂëäÂíåÂõæË°®"""
        try:
            # Ëé∑ÂèñÊñá‰ª∂‰ø°ÊÅØ
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('SELECT file_path, file_type, filename FROM files WHERE id = ?', (file_id,))
            result = cursor.fetchone()
            conn.close()

            if not result:
                return {"success": False, "error": "Êñá‰ª∂‰∏çÂ≠òÂú®"}

            file_path, file_type, filename = result

            # ÊèêÂèñÊñáÊú¨ÂÜÖÂÆπ
            text = self.extract_text_from_file(file_id)
            if not text:
                return {"success": False, "error": "Êó†Ê≥ïÊèêÂèñÊñáÊú¨ÂÜÖÂÆπ"}

            # ÂàÜÊûêÊñáÊ°£ÁªìÊûÑ
            analysis = self.analyze_document_structure(text)
            analysis["full_text"] = text

            # ÊèêÂèñÊï∞ÊçÆÁÇπ
            data_points = self.extract_data_points(text)

            # ÁîüÊàêÂõæË°®
            charts = self.generate_charts(data_points)

            # ÁîüÊàêÊä•Âëä
            report = self.create_smart_report(analysis, charts, filename)

            return {
                "success": True,
                "analysis": analysis,
                "data_points": data_points,
                "charts": charts,
                "report": report
            }

        except Exception as e:
            return {"success": False, "error": str(e)}

    def generate_ai_report(self, file_id: int, user_question) -> Dict[str, Any]:
        """ÁîüÊàêÊô∫ËÉΩÊä•ÂëäÂíåÂõæË°®"""
        try:
            start_time = time.time()
            # Ëé∑ÂèñÊñá‰ª∂‰ø°ÊÅØ
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('SELECT file_path, file_type, filename FROM files WHERE id = ?', (file_id,))
            result = cursor.fetchone()
            conn.close()

            if not result:
                return {"success": False, "error": "Êñá‰ª∂‰∏çÂ≠òÂú®"}

            file_path, file_type, filename = result

            # ÊèêÂèñÊñáÊú¨ÂÜÖÂÆπ
            df = self.extract_excel_csv(file_id)
            analyzer = SmartAnalysisGenerator(df)

            # Generate smart analysis based on request
            ai_code = analyzer.generate_smart_analysis(user_question)
            generation_time = time.time() - start_time

            st.success(f"‚úÖ Analysis ready in {generation_time:.2f}s!")

            # Execute code
            try:
                plt.close('all')
                output_buffer = io.StringIO()

                with contextlib.redirect_stdout(output_buffer):
                    with contextlib.redirect_stderr(io.StringIO()):
                        exec_globals = {
                            'df': df, 'plt': plt, 'sns': sns, 'pd': pd, 'np': np,
                            'print': print, 'len': len, 'str': str, 'list': list, 'dict': dict
                        }
                        exec(ai_code, exec_globals)

                output_text = output_buffer.getvalue()

                # Display insights
                if output_text.strip():
                    st.markdown("#### üìù Analysis Insights")
                    st.text_area("", output_text, height=200, label_visibility="collapsed")

                # Display visualizations
                if plt.get_fignums():
                    st.markdown("#### üìà Visualizations")
                    for fig_num in plt.get_fignums():
                        plt.figure(fig_num)
                        st.pyplot(plt)

            except Exception as e:
                st.error(f"‚ùå Error during execution: {str(e)}")

            # Show code
            with st.expander("üîß View Analysis Code"):
                st.code(ai_code, language='python')

            return {
                "success": True,
            }
        except Exception as e:
            return {"success": False, "error": str(e)}



    def analyze_document_structure(self, text: str) -> Dict[str, Any]:
        """ÂàÜÊûêÊñáÊ°£ÁªìÊûÑÔºåËØÜÂà´ÂÜú‰∏öÈ¢ÜÂüüÊñáÊ°£Á±ªÂûã‰∏éË¶ÅÁ¥†"""
        analysis = {
            "document_type": "Êú™Áü•",
            "data_types": [],
            "key_metrics": [],
            "time_periods": [],
            "categories": [],
            "confidence": 0.0
        }

        # ËØÜÂà´ÂÜú‰∏öÊñáÊ°£Á±ªÂûã
        if any(k in text for k in ["Âçï‰∫ß", "‰∫©‰∫ß", "t/ha", "kg/ha", "Êí≠ÁßçÈù¢ÁßØ", "Êî∂Ëé∑Èù¢ÁßØ", "‰∫ßÈáè"]):
            analysis["document_type"] = "ÁßçÊ§ç‰∏öÁîü‰∫ßÊä•Âëä"
            analysis["data_types"].extend(["Èù¢ÁßØ", "‰∫ßÈáè", "Âçï‰∫ß", "Ë∂ãÂäø"])
        elif any(k in text for k in ["Âá∫Ê†è", "Â≠òÊ†è", "Â¢ûÈáç", "Êó•Â¢ûÈáç", "ÊñôËÇâÊØî", "ÂÖçÁñ´"]):
            analysis["document_type"] = "ÁïúÁâß‰∏öÁîü‰∫ßÊä•Âëä"
            analysis["data_types"].extend(["Â§¥Êï∞", "ÈáçÈáè", "ËΩ¨Êç¢Áéá", "ÂÖçÁñ´"])
        elif any(k in text for k in ["ÈôçÈõ®", "ÈôçÊ∞¥", "mm", "ÁßØÊ∏©", "Âπ≤Êó±", "NDVI", "ÈÅ•ÊÑü"]):
            analysis["document_type"] = "Ê∞îÂÄô‰∏éÈÅ•ÊÑüÁõëÊµã"
            analysis["data_types"].extend(["ÈôçÈõ®", "Ê∏©Â∫¶", "ÊåáÊï∞", "Êó∂Èó¥Â∫èÂàó"])
        elif any(k in text for k in ["ÊàêÊú¨", "ÈááË¥≠", "‰ª∑Ê†º", "‰øùÈô©", "Ëµî‰ªò", "Âà©Ê∂¶", "ÊØõÂà©Áéá"]):
            analysis["document_type"] = "ÂÜú‰∏öË¥¢Âä°/‰æõÂ∫îÈìæÊä•Âëä"
            analysis["data_types"].extend(["ÈáëÈ¢ù", "ÊØîÁéá", "ÂØπÊØî", "‰ª∑Ê†ºË∂ãÂäø"])

        # ÊèêÂèñÂÖ≥ÈîÆÊåáÊ†á
        import re
        # Êü•ÊâæÊï∞Â≠óÊ®°ÂºèÔºàÊîØÊåÅÂ∏¶Âçï‰ΩçÔºâ
        numbers = re.findall(r'[\d,]+\.?\d*\s*(?:t/ha|kg/ha|kg|t|Âê®|ÂÖ¨Êñ§|ÂÖÉ/Êñ§|ÂÖÉ/Âê®|mm)?', text)
        analysis["key_metrics"] = numbers[:10]  # ÂèñÂâç10‰∏™Êï∞Â≠ó

        # Êü•ÊâæÊó∂Èó¥Ê®°Âºè
        time_patterns = re.findall(r'\d{4}Âπ¥|\d{1,2}Êúà|\d{1,2}Êó•|Q[1-4]', text)
        analysis["time_periods"] = list(set(time_patterns))

        # Êü•ÊâæÂàÜÁ±ª‰ø°ÊÅØ
        category_patterns = re.findall(r'[A-Za-z\u4e00-\u9fff]+[Ôºö:]\s*[\d,]+', text)
        analysis["categories"] = category_patterns[:5]

        # ËÆ°ÁÆóÁΩÆ‰ø°Â∫¶ÔºàÂÜú‰∏öÂú∫ÊôØÁ®çÂæÆÊèêÈ´òÂÖ≥ÈîÆÊåáÊ†áÊùÉÈáçÔºâ
        confidence = min(len(analysis["key_metrics"]) * 0.12 +
                         len(analysis["time_periods"]) * 0.18 +
                         len(analysis["categories"]) * 0.1, 1.0)
        analysis["confidence"] = confidence

        return analysis

    def extract_data_points(self, text: str) -> List[Dict[str, Any]]:
        """ÊèêÂèñÊï∞ÊçÆÁÇπÁî®‰∫éÁîüÊàêÂõæË°®ÔºàÂ¢ûÂº∫ÂÜú‰∏öÂçï‰ΩçËØÜÂà´Ôºâ"""
        data_points = []

        import re

        # ÊèêÂèñÊï∞ÂÄºÂíåÊ†áÁ≠æ
        patterns = [
            r'([A-Za-z\u4e00-\u9fff]+)[Ôºö:]\s*([\d,]+\.?\d*)\s*(t/ha|kg/ha|kg|t|Âê®|ÂÖ¨Êñ§|mm|%)?',
            r'([A-Za-z\u4e00-\u9fff]+)\s*([\d,]+\.?\d*)\s*(%)',
            r'([A-Za-z\u4e00-\u9fff]+)\s*‰∏∫\s*([\d,]+\.?\d*)\s*(t/ha|kg/ha|kg|t|Âê®|ÂÖ¨Êñ§|mm|%)?'
        ]

        for pattern in patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if len(match) == 3:
                    label, value, unit = match
                else:
                    label, value = match
                    unit = None
                try:
                    # Ê∏ÖÁêÜÊï∞ÂÄº
                    clean_value = float(value.replace(',', ''))
                    if clean_value > 0:  # Âè™‰øùÁïôÊ≠£Êï∞
                        data_points.append({
                            "label": label.strip(),
                            "value": clean_value,
                            "type": unit or "Êï∞ÂÄº"
                        })
                except ValueError:
                    continue

        # ÂéªÈáçÂπ∂ÊéíÂ∫è
        seen = set()
        unique_points = []
        for point in data_points:
            key = point["label"]
            if key not in seen:
                seen.add(key)
                unique_points.append(point)

        # ÊåâÊï∞ÂÄºÊéíÂ∫è
        unique_points.sort(key=lambda x: x["value"], reverse=True)

        return unique_points[:10]  # ËøîÂõûÂâç10‰∏™Êï∞ÊçÆÁÇπ

    def generate_charts(self, data_points: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ÁîüÊàêÂõæË°®Êï∞ÊçÆ"""
        charts = []

        if not data_points:
            return charts

        # ÁîüÊàêÊü±Áä∂ÂõæÊï∞ÊçÆ
        if len(data_points) >= 2:
            bar_chart = {
                "type": "bar",
                "title": "Êï∞ÊçÆÂØπÊØîÊü±Áä∂Âõæ",
                "data": {
                    "labels": [point["label"] for point in data_points[:8]],
                    "values": [point["value"] for point in data_points[:8]]
                }
            }
            charts.append(bar_chart)

        # ÁîüÊàêÈ•ºÂõæÊï∞ÊçÆÔºàÂâç5‰∏™Ôºâ
        if len(data_points) >= 3:
            pie_data = data_points[:5]
            total = sum(point["value"] for point in pie_data)
            pie_chart = {
                "type": "pie",
                "title": "Êï∞ÊçÆÂàÜÂ∏ÉÈ•ºÂõæ",
                "data": {
                    "labels": [point["label"] for point in pie_data],
                    "values": [point["value"] for point in pie_data],
                    "percentages": [round(point["value"] / total * 100, 1) for point in pie_data]
                }
            }
            charts.append(pie_chart)

        # ÁîüÊàêË∂ãÂäøÂõæÔºàÂ¶ÇÊûúÊúâÊó∂Èó¥Êï∞ÊçÆÔºâ
        if len(data_points) >= 4:
            line_chart = {
                "type": "line",
                "title": "Êï∞ÊçÆË∂ãÂäøÂõæ",
                "data": {
                    "labels": [point["label"] for point in data_points[:6]],
                    "values": [point["value"] for point in data_points[:6]]
                }
            }
            charts.append(line_chart)

        return charts

    def create_smart_report(self, analysis: Dict, charts: List[Dict], filename: str) -> str:
        """ÁîüÊàêÊô∫ËÉΩÊä•ÂëäÔºàÂä†ÂÖ•ÂÜú‰∏öÊ¥ûÂØü‰∏éKPIÔºâ"""
        report = f"# üìä Agribusiness Smart Analysis Report\n\n"
        report += f"**File name**: {filename}\n\n"
        report += f"**Document type**: {analysis['document_type']}\n\n"
        report += f"**Confidence**: {analysis['confidence']:.1%}\n\n"

        # ÂÜú‰∏öKPIÔºà‰ªéÂÖ®ÊñáÊô∫ËÉΩÊèêÂèñÔºâ
        agrikpis = self.compute_agribusiness_kpis(analysis.get('full_text', '')) if isinstance(analysis, dict) else {}
        if agrikpis:
            report += "## üåæ Agribusiness KPIs\n\n"
            for k, v in agrikpis.items():
                report += f"- {k}: {v}\n"
            report += "\n"

        # Â§©Ê∞îÊëòË¶ÅÔºàÂ¶ÇÊûúÂ∑≤Ëé∑ÂèñÔºâ
        if getattr(self, 'latest_weather', None):
            ws = self.latest_weather.get('summary', {})
            report += "## ‚òÅÔ∏è Climate summary (next 7 days)\n\n"
            if ws:
                if ws.get('7d_total_rain_mm') is not None:
                    report += f"- Total rainfall: {ws['7d_total_rain_mm']} mm\n"
                if ws.get('avg_tmax') is not None:
                    report += f"- Avg Tmax: {ws['avg_tmax']} ¬∞C\n"
                if ws.get('avg_tmin') is not None:
                    report += f"- Avg Tmin: {ws['avg_tmin']} ¬∞C\n"
            report += "\n"

        # ÈÅ•ÊÑüÊëòË¶ÅÔºàÂ¶ÇÊûúÂ∑≤Ëé∑ÂèñÔºâ
        if getattr(self, 'latest_remote_sensing', None):
            rs = self.latest_remote_sensing.get('summary', {})
            report += "## üõ∞Ô∏è Remote sensing summary\n\n"
            if rs:
                if rs.get('ndvi_avg') is not None:
                    report += f"- NDVI average: {rs['ndvi_avg']}\n"
                if rs.get('evi_avg') is not None:
                    report += f"- EVI average: {rs['evi_avg']}\n"
                if rs.get('ndvi_last') is not None:
                    report += f"- Latest NDVI: {rs['ndvi_last']}\n"
                if rs.get('evi_last') is not None:
                    report += f"- Latest EVI: {rs['evi_last']}\n"
            report += "\n"

        # Ê®°ÊùøÊäΩÂèñÁªìÊûú
        structured = self.extract_agri_structured_fields(analysis.get('full_text', '')) if isinstance(analysis,
                                                                                                      dict) else {}
        if structured:
            report += "## üóÇÔ∏è Structured fields (template extraction)\n\n"
            for k, v in structured.items():
                report += f"- {k}: {v}\n"
            report += "\n"

        # Key metrics
        if analysis['key_metrics']:
            report += "## üî¢ Key metrics\n\n"
            for i, metric in enumerate(analysis['key_metrics'][:5], 1):
                report += f"{i}. {metric}\n"
            report += "\n"

        # Time periods
        if analysis['time_periods']:
            report += "## üìÖ Time periods\n\n"
            report += f"Detected time info: {', '.join(analysis['time_periods'])}\n\n"

        # Categories
        if analysis['categories']:
            report += "## üìã Categories\n\n"
            for category in analysis['categories']:
                report += f"- {category}\n"
            report += "\n"

        # Visualization notes
        if charts:
            report += "## üìà Data visualization\n\n"
            for chart in charts:
                report += f"### {chart['title']}\n\n"
                if chart['type'] == 'bar':
                    report += "Bar chart shows value comparison across categories to spot highs and lows.\n\n"
                elif chart['type'] == 'pie':
                    report += "Pie chart shows proportion distribution for intuitive share comparison.\n\n"
                elif chart['type'] == 'line':
                    report += "Line chart shows temporal trends to identify growth or decline patterns.\n\n"

        # Suggestions
        report += "## üí° Suggestions\n\n"
        if analysis['document_type'] in ["ÁßçÊ§ç‰∏öÁîü‰∫ßÊä•Âëä", "ÁïúÁâß‰∏öÁîü‰∫ßÊä•Âëä"]:
            report += "- Track trends of key KPIs (yield, rainfall, FCR).\n"
            report += "- Compare fields/lots or herds to find outliers.\n"
            report += "- Plan interventions (fertigation, pest control) based on thresholds.\n"
        elif analysis['document_type'] in ["ÂÜú‰∏öË¥¢Âä°/‰æõÂ∫îÈìæÊä•Âëä"]:
            report += "- Monitor margins and price trends.\n"
            report += "- Optimize cost structure and inventory turnover.\n"
            report += "- Manage risk with insurance/hedging where applicable.\n"
        else:
            report += "- Keep data updated regularly.\n"
            report += "- Focus on KPI trends and anomalies.\n"
            report += "- Apply data-driven decisions.\n"

        return report

    def compute_agribusiness_kpis(self, text: str) -> Dict[str, Any]:
        """Âü∫‰∫éËßÑÂàôÂø´ÈÄüÊèêÂèñÂÜú‰∏öÂ∏∏ËßÅKPIÔºàËΩªÈáèÂç†‰ΩçÔºåÂèØÂêéÁª≠Êç¢Ê®°ÂûãÔºâ"""
        if not text:
            return {}
        import re
        kpis: Dict[str, Any] = {}
        try:
            # Âçï‰∫ßÔºàÊîØÊåÅ kg/ha, t/ha, ‰∫©‰∫ßÔºâ
            m = re.search(r'(Âçï‰∫ß|‰∫©‰∫ß)[:Ôºö]?\s*([\d,.]+)\s*(kg/ha|t/ha|ÂÖ¨Êñ§/‰∫©|Êñ§/‰∫©|Âê®/ÂÖ¨È°∑)?', text)
            if m:
                kpis['Âçï‰∫ß'] = f"{m.group(2)} {m.group(3) or ''}".strip()

            # Èù¢ÁßØÔºà‰∫©„ÄÅÂÖ¨È°∑Ôºâ
            m = re.search(r'(Êí≠ÁßçÈù¢ÁßØ|Êî∂Ëé∑Èù¢ÁßØ|Èù¢ÁßØ)[:Ôºö]?\s*([\d,.]+)\s*(‰∫©|ÂÖ¨È°∑|ha)', text)
            if m:
                kpis['Èù¢ÁßØ'] = f"{m.group(2)} {m.group(3)}"

            # ÈôçÈõ®ÈáèÔºàmmÔºâ
            m = re.search(r'(ÈôçÈõ®|ÈôçÊ∞¥|Á¥ØËÆ°ÈôçÈõ®|Á¥ØËÆ°ÈôçÊ∞¥)[:Ôºö]?\s*([\d,.]+)\s*mm', text)
            if m:
                kpis['Á¥ØËÆ°ÈôçÈõ®'] = f"{m.group(2)} mm"

            # ÊàêÊú¨‰∏éÂà©Ê∂¶
            m = re.search(r'(ÊÄªÊàêÊú¨|ÊàêÊú¨)[:Ôºö]?\s*([\d,.]+)', text)
            if m:
                kpis['ÊàêÊú¨'] = m.group(2)
            m = re.search(r'(Âà©Ê∂¶|ÊØõÂà©|ÊØõÂà©Áéá)[:Ôºö]?\s*([\d,.]+)\s*(%)?', text)
            if m:
                kpis['Âà©Ê∂¶/ÊØõÂà©'] = f"{m.group(2)}{m.group(3) or ''}"

            # ÁïúÁâßÂÖ≥ÈîÆÊåáÊ†á
            m = re.search(r'(Âá∫Ê†è|Â≠òÊ†è)[:Ôºö]?\s*([\d,.]+)\s*(Â§¥|Âè™)?', text)
            if m:
                kpis[m.group(1)] = f"{m.group(2)} {m.group(3) or ''}".strip()
            m = re.search(r'(ÊñôËÇâÊØî|FCR)[:Ôºö]?\s*([\d,.]+)', text)
            if m:
                kpis['ÊñôËÇâÊØî'] = m.group(2)

            # ÈÅ•ÊÑüÊåáÊï∞
            m = re.search(r'(NDVI|EVI)[:Ôºö]?\s*([\d,.]+)', text)
            if m:
                kpis[m.group(1)] = m.group(2)
        except Exception:
            pass
        return kpis

    def calculate_checksum(self, file_path: str) -> str:
        """ËÆ°ÁÆóÊñá‰ª∂Ê†°È™åÂíå"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()

    def get_file_type(self, filename: str) -> str:
        """Ëé∑ÂèñÊñá‰ª∂Á±ªÂûã"""
        mime_type, _ = mimetypes.guess_type(filename)
        if mime_type:
            return mime_type.split('/')[0]
        return 'unknown'

    def upload_file(self, uploaded_file, folder_id: Optional[int] = None) -> Dict[str, Any]:
        """‰∏ä‰º†Êñá‰ª∂"""
        try:
            # ÁîüÊàêÂîØ‰∏ÄÊñá‰ª∂Âêç
            timestamp = int(time.time())
            filename = f"{timestamp}_{uploaded_file.name}"
            file_path = self.storage_dir / filename

            # ‰øùÂ≠òÊñá‰ª∂
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            # ËÆ°ÁÆóÊñá‰ª∂‰ø°ÊÅØ
            file_size = file_path.stat().st_size
            checksum = self.calculate_checksum(str(file_path))
            file_type = self.get_file_type(uploaded_file.name)

            # ‰øùÂ≠òÂà∞Êï∞ÊçÆÂ∫ì
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO files (filename, file_path, file_size, file_type, folder_id, checksum)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (uploaded_file.name, str(file_path), file_size, file_type, folder_id, checksum))
            conn.commit()
            conn.close()

            return {
                "success": True,
                "filename": uploaded_file.name,
                "file_size": file_size,
                "file_type": file_type
            }
        except Exception as e:
            return {"success": False, "error": str(e)}

    def get_files(self, folder_id: Optional[int] = None) -> List[Dict[str, Any]]:
        """Ëé∑ÂèñÊñá‰ª∂ÂàóË°®"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        if folder_id is None:
            cursor.execute('''
                SELECT id, filename, file_size, file_type, upload_time, is_cached
                FROM files WHERE folder_id IS NULL
                ORDER BY upload_time DESC
            ''')
        else:
            cursor.execute('''
                SELECT id, filename, file_size, file_type, upload_time, is_cached
                FROM files WHERE folder_id = ?
                ORDER BY upload_time DESC
            ''', (folder_id,))

        files = []
        for row in cursor.fetchall():
            files.append({
                "id": row[0],
                "filename": row[1],
                "file_size": row[2],
                "file_type": row[3],
                "upload_time": row[4],
                "is_cached": bool(row[5])
            })

        conn.close()
        return files

    def create_folder(self, folder_name: str, parent_folder_id: Optional[int] = None) -> Dict[str, Any]:
        """ÂàõÂª∫Êñá‰ª∂Â§π"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO folders (folder_name, parent_folder_id)
                VALUES (?, ?)
            ''', (folder_name, parent_folder_id))
            conn.commit()
            folder_id = cursor.lastrowid
            conn.close()

            return {"success": True, "folder_id": folder_id}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def search_files(self, query: str, file_type: Optional[str] = None) -> List[Dict[str, Any]]:
        """ÊêúÁ¥¢Êñá‰ª∂"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        if file_type:
            cursor.execute('''
                SELECT id, filename, file_size, file_type, upload_time, is_cached
                FROM files 
                WHERE filename LIKE ? AND file_type = ?
                ORDER BY upload_time DESC
            ''', (f"%{query}%", file_type))
        else:
            cursor.execute('''
                SELECT id, filename, file_size, file_type, upload_time, is_cached
                FROM files 
                WHERE filename LIKE ?
                ORDER BY upload_time DESC
            ''', (f"%{query}%",))

        files = []
        for row in cursor.fetchall():
            files.append({
                "id": row[0],
                "filename": row[1],
                "file_size": row[2],
                "file_type": row[3],
                "upload_time": row[4],
                "is_cached": bool(row[5])
            })

        conn.close()
        return files

    def preview_file(self, file_id: int) -> Optional[bytes]:
        """È¢ÑËßàÊñá‰ª∂"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT file_path, file_type FROM files WHERE id = ?', (file_id,))
        result = cursor.fetchone()
        conn.close()

        if not result:
            return None

        file_path, file_type = result

        try:
            with open(file_path, 'rb') as f:
                return f.read()
        except:
            return None

    def cache_file(self, file_id: int) -> bool:
        """ÁºìÂ≠òÊñá‰ª∂Âà∞Êú¨Âú∞"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('SELECT file_path, filename FROM files WHERE id = ?', (file_id,))
            result = cursor.fetchone()

            if result:
                file_path, filename = result
                cache_path = self.cache_dir / filename
                shutil.copy2(file_path, cache_path)

                # Êõ¥Êñ∞Êï∞ÊçÆÂ∫ì
                cursor.execute('UPDATE files SET is_cached = TRUE WHERE id = ?', (file_id,))
                conn.commit()
                conn.close()
                return True
        except:
            pass
        return False

    def format_file_size(self, size_bytes: int) -> str:
        """Ê†ºÂºèÂåñÊñá‰ª∂Â§ßÂ∞è"""
        if size_bytes == 0:
            return "0B"
        size_names = ["B", "KB", "MB", "GB", "TB"]
        i = 0
        while size_bytes >= 1024 and i < len(size_names) - 1:
            size_bytes /= 1024.0
            i += 1
        return f"{size_bytes:.1f}{size_names[i]}"

    def get_file_icon(self, file_type: str) -> str:
        """Ëé∑ÂèñÊñá‰ª∂Á±ªÂûãÂõæÊ†á"""
        icons = {
            'image': 'üñºÔ∏è',
            'application': 'üìÑ',
            'text': 'üìù',
            'video': 'üé•',
            'audio': 'üéµ',
            'unknown': 'üìÅ'
        }
        return icons.get(file_type, 'üìÅ')

    def upload_file_with_resume(self, uploaded_file, folder_id: Optional[int] = None, chunk_size: int = 1024 * 1024) -> \
    Dict[str, Any]:
        """Â∏¶Êñ≠ÁÇπÁª≠‰º†ÁöÑÊñá‰ª∂‰∏ä‰º†"""
        try:
            filename = uploaded_file.name
            file_size = len(uploaded_file.getbuffer())

            # Ê£ÄÊü•ÊòØÂê¶ÊúâÊú™ÂÆåÊàêÁöÑ‰∏ä‰º†
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                SELECT id, uploaded_size, checksum FROM upload_progress 
                WHERE filename = ? AND total_size = ?
                ORDER BY upload_time DESC LIMIT 1
            ''', (filename, file_size))

            progress_record = cursor.fetchone()

            if progress_record:
                # Êñ≠ÁÇπÁª≠‰º†
                progress_id, uploaded_size, stored_checksum = progress_record
                st.info(f"üîÑ Resumable upload found, continue from {uploaded_size} bytes...")
            else:
                # Êñ∞‰∏ä‰º†
                uploaded_size = 0
                progress_id = None
                stored_checksum = None

            # ÂàÜÂùó‰∏ä‰º†
            uploaded_file.seek(uploaded_size)
            current_size = uploaded_size

            progress_bar = st.progress(uploaded_size / file_size)
            status_text = st.empty()

            while current_size < file_size:
                chunk = uploaded_file.read(min(chunk_size, file_size - current_size))
                if not chunk:
                    break

                # ËøôÈáåÂ∫îËØ•Â∞ÜchunkÂèëÈÄÅÂà∞ÊúçÂä°Âô®
                # ‰∏∫‰∫ÜÊºîÁ§∫ÔºåÊàë‰ª¨Áõ¥Êé•ÂÜôÂÖ•Êú¨Âú∞Êñá‰ª∂
                temp_file_path = self.storage_dir / f"temp_{filename}"
                with open(temp_file_path, "ab") as f:
                    f.write(chunk)

                current_size += len(chunk)
                progress = current_size / file_size
                progress_bar.progress(progress)
                status_text.text(f"Uploading: {current_size}/{file_size} bytes ({progress * 100:.1f}%)")

                # Êõ¥Êñ∞ËøõÂ∫¶Âà∞Êï∞ÊçÆÂ∫ì
                if progress_id:
                    cursor.execute('''
                        UPDATE upload_progress 
                        SET uploaded_size = ? 
                        WHERE id = ?
                    ''', (current_size, progress_id))
                else:
                    cursor.execute('''
                        INSERT INTO upload_progress (filename, total_size, uploaded_size, chunk_size, checksum)
                        VALUES (?, ?, ?, ?, ?)
                    ''', (filename, file_size, current_size, chunk_size, stored_checksum))
                    progress_id = cursor.lastrowid

                conn.commit()

                # Ê®°ÊãüÁΩëÁªúÂª∂Ëøü
                time.sleep(0.1)

            # ‰∏ä‰º†ÂÆåÊàêÔºåÁßªÂä®Êñá‰ª∂Âà∞ÊúÄÁªà‰ΩçÁΩÆ
            final_file_path = self.storage_dir / f"{int(time.time())}_{filename}"
            shutil.move(str(temp_file_path), str(final_file_path))

            # ËÆ°ÁÆóÊ†°È™åÂíå
            checksum = self.calculate_checksum(str(final_file_path))
            file_type = self.get_file_type(filename)

            # ‰øùÂ≠òÊñá‰ª∂‰ø°ÊÅØÂà∞Êï∞ÊçÆÂ∫ì
            cursor.execute('''
                INSERT INTO files (filename, file_path, file_size, file_type, folder_id, checksum)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (filename, str(final_file_path), file_size, file_type, folder_id, checksum))

            # Âà†Èô§ËøõÂ∫¶ËÆ∞ÂΩï
            if progress_id:
                cursor.execute('DELETE FROM upload_progress WHERE id = ?', (progress_id,))

            conn.commit()
            conn.close()

            progress_bar.empty()
            status_text.empty()

            return {
                "success": True,
                "filename": filename,
                "file_size": file_size,
                "file_type": file_type,
                "checksum": checksum
            }

        except Exception as e:
            return {"success": False, "error": str(e)}

    def get_upload_progress(self) -> List[Dict[str, Any]]:
        """Ëé∑Âèñ‰∏ä‰º†ËøõÂ∫¶ÂàóË°®"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            SELECT filename, total_size, uploaded_size, upload_time
            FROM upload_progress
            ORDER BY upload_time DESC
        ''')

        progress_list = []
        for row in cursor.fetchall():
            filename, total_size, uploaded_size, upload_time = row
            progress_list.append({
                "filename": filename,
                "total_size": total_size,
                "uploaded_size": uploaded_size,
                "progress": uploaded_size / total_size if total_size > 0 else 0,
                "upload_time": upload_time
            })

        conn.close()
        return progress_list

    def resume_upload(self, filename: str) -> Dict[str, Any]:
        """ÊÅ¢Â§ç‰∏ä‰º†"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            SELECT id, total_size, uploaded_size, chunk_size, checksum
            FROM upload_progress 
            WHERE filename = ?
            ORDER BY upload_time DESC LIMIT 1
        ''', (filename,))

        result = cursor.fetchone()
        if result:
            progress_id, total_size, uploaded_size, chunk_size, checksum = result
            return {
                "success": True,
                "progress_id": progress_id,
                "total_size": total_size,
                "uploaded_size": uploaded_size,
                "chunk_size": chunk_size,
                "checksum": checksum
            }
        else:
            return {"success": False, "error": "Êú™ÊâæÂà∞‰∏ä‰º†ËøõÂ∫¶ËÆ∞ÂΩï"}

    def cancel_upload(self, filename: str) -> bool:
        """ÂèñÊ∂à‰∏ä‰º†"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('DELETE FROM upload_progress WHERE filename = ?', (filename,))
            conn.commit()
            conn.close()
            return True
        except:
            return False

    # ==================== AIÂäüËÉΩÊñπÊ≥ï ====================
    def extract_excel_csv(self, file_id: int):
        """
        ÈÄöËøáfile_idËØªÂèñExcel(.xlsx, .xls)ÊàñCSVÊñá‰ª∂ÔºåËøîÂõûPandas DataFrame
        ÈùûÊîØÊåÅÁ±ªÂûã/ËØªÂèñÂ§±Ë¥•Êó∂ËøîÂõûNoneÔºåÂπ∂ÊòæÁ§∫StreamlitÊèêÁ§∫
        """
        # 1. ‰ªéÊï∞ÊçÆÂ∫ìÊü•ËØ¢Êñá‰ª∂‰ø°ÊÅØ
        conn = None
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            # Êü•ËØ¢Êñá‰ª∂Ë∑ØÂæÑ„ÄÅÁ±ªÂûã„ÄÅÊñá‰ª∂ÂêçÔºà‰∏éÊï∞ÊçÆÂ∫ìË°®ÁªìÊûÑÂØπÂ∫îÔºâ
            cursor.execute(
                'SELECT file_path, file_type, filename FROM files WHERE id = ?',
                (file_id,)
            )
            result = cursor.fetchone()
            if not result:
                st.error("File not found in database (invalid file ID).")
                return None  # Êñá‰ª∂‰∏çÂ≠òÂú®ÔºåËøîÂõûNone

            file_path, file_type, filename = result
            filename = filename.lower()  # Áªü‰∏ÄËΩ¨‰∏∫Â∞èÂÜôÔºåÈÅøÂÖçÂ§ßÂ∞èÂÜôÂà§Êñ≠ÈóÆÈ¢ò

            # 2. Ê†°È™åÊñá‰ª∂Á±ªÂûãÔºà‰ªÖÊîØÊåÅExcelÂíåCSVÔºâ
            if filename.endswith(('.xlsx', '.xls')):
                # 3. ËØªÂèñExcelÊñá‰ª∂
                try:
                    df = pd.read_excel(file_path)
                    if df.empty:
                        st.warning("The Excel file is empty.")
                        return None
                    return df
                except FileNotFoundError:
                    st.error(f"Excel file not found at path: {file_path}")
                except pd.errors.EmptyDataError:
                    st.error("Excel file contains no valid data.")
                except pd.errors.ParserError:
                    st.error("Failed to parse Excel file (may be corrupted).")
                except Exception as e:
                    st.error(f"Error reading Excel file: {str(e)}")

            elif filename.endswith('.csv'):
                # 3. ËØªÂèñCSVÊñá‰ª∂
                try:
                    # Â∞ùËØïÂ∏∏Áî®ÁºñÁ†ÅÔºåÈÅøÂÖç‰∏≠Êñá‰π±Á†ÅÂØºËá¥ËØªÂèñÂ§±Ë¥•
                    df = pd.read_csv(file_path, encoding='utf-8')
                except UnicodeDecodeError:
                    # ÁºñÁ†ÅÈîôËØØÊó∂Â∞ùËØïgbkÔºàÈÄÇÂêà‰∏≠ÊñáÁéØÂ¢ÉÔºâ
                    try:
                        df = pd.read_csv(file_path, encoding='gbk')
                    except Exception as e:
                        st.error(f"CSV file encoding error: {str(e)}")
                        return None
                except FileNotFoundError:
                    st.error(f"CSV file not found at path: {file_path}")
                    return None
                except pd.errors.EmptyDataError:
                    st.error("CSV file contains no valid data.")
                    return None
                except pd.errors.ParserError:
                    st.error("Failed to parse CSV file (may be corrupted).")
                    return None
                except Exception as e:
                    st.error(f"Error reading CSV file: {str(e)}")
                    return None

                if df.empty:
                    st.warning("The CSV file is empty.")
                    return None
                return df

            else:
                # ÈùûÊîØÊåÅÁ±ªÂûãÔºåÊòæÁ§∫Ëã±ÊñáÊèêÁ§∫
                st.error("Unsupported file type. Only Excel (.xlsx, .xls) and CSV files are supported.")
                return None

        except sqlite3.Error as db_err:
            st.error(f"Database error: {str(db_err)} (failed to get file info)")
            return None
        finally:
            # Á°Æ‰øùÊï∞ÊçÆÂ∫ìËøûÊé•ÂÖ≥Èó≠
            if conn:
                conn.close()
        return None

    def extract_text_from_file(self, file_id: int) -> str:
        """‰ªéÊñá‰ª∂‰∏≠ÊèêÂèñÊñáÊú¨ÂÜÖÂÆπ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT file_path, file_type, filename FROM files WHERE id = ?', (file_id,))
        result = cursor.fetchone()
        conn.close()

        if not result:
            return ""

        file_path, file_type, filename = result
        extracted_text = ""

        try:
            if file_type == 'text' or filename.endswith('.txt'):
                # ÊñáÊú¨Êñá‰ª∂
                with open(file_path, 'r', encoding='utf-8') as f:
                    extracted_text = f.read()

            elif file_type == 'application' and filename.endswith('.pdf'):
                # PDFÊñá‰ª∂
                if PDF_AVAILABLE:
                    doc = fitz.open(file_path)
                    for page in doc:
                        extracted_text += page.get_text()
                    doc.close()
                # Ëã•‰∏çÂèØÁî®Âàô‰øùÊåÅ‰∏∫Á©∫ÔºåÂêéÁª≠ÁªôÂá∫ÂèãÂ•ΩÂç†‰Ωç

            elif file_type == 'application' and filename.endswith(('.xlsx', '.xls')):
                # ExcelÊñá‰ª∂
                try:
                    df = pd.read_excel(file_path)
                    # Á°Æ‰øùDataFrame‰∏ç‰∏∫Á©∫
                    if not df.empty:
                        # ÂÆâÂÖ®Âú∞ËΩ¨Êç¢‰∏∫Â≠óÁ¨¶‰∏≤ÔºåÈÅøÂÖçnumpy.str_ÈîôËØØ
                        try:
                            extracted_text = df.to_string()
                        except Exception as str_error:
                            # Â¶ÇÊûúto_stringÂ§±Ë¥•ÔºåÂ∞ùËØïÂÖ∂‰ªñÊñπÊ≥ï
                            extracted_text = str(df.values.tolist())
                    else:
                        extracted_text = "Excel file is empty"
                except Exception as e:
                    st.warning(f"Excel reading failed: {str(e)}")
                    extracted_text = ""

            elif filename.endswith('.csv'):
                # CSVÊñá‰ª∂
                try:
                    df = pd.read_csv(file_path)
                    if not df.empty:
                        try:
                            extracted_text = df.to_string()
                        except Exception:
                            extracted_text = str(df.values.tolist())
                    else:
                        extracted_text = "CSV file is empty"
                except Exception as e:
                    st.warning(f"CSV reading failed: {str(e)}")
                    extracted_text = ""

            elif filename.endswith('.docx'):
                # DOCXÔºàÂèØÈÄâÂ§ÑÁêÜÔºâ
                try:
                    import docx  # type: ignore
                    doc = docx.Document(file_path)
                    paras = [p.text for p in doc.paragraphs if p.text]
                    extracted_text = "\n".join(paras)
                except Exception:
                    # Êú™ÂÆâË£ÖÊàñËß£ÊûêÂ§±Ë¥•ÂàôÂøΩÁï•
                    pass

            elif file_type == 'image':
                # ÂõæÁâáÊñá‰ª∂ - OCRËØÜÂà´
                if OCR_AVAILABLE:
                    if self.ocr_reader is None:
                        # Âª∂ËøüÂä†ËΩΩOCRÊ®°Âûã
                        st.info("üîÑ Loading OCR model, please wait...")
                        try:
                            self.ocr_reader = easyocr.Reader(['ch_sim', 'en'])
                            st.success("‚úÖ OCR model loaded")
                        except Exception as e:
                            st.error(f"OCR model load failed: {str(e)}")
                            return ""

                    if self.ocr_reader:
                        results = self.ocr_reader.readtext(file_path)
                        extracted_text = ' '.join([result[1] for result in results])

        except Exception as e:
            st.error(f"Text extraction failed: {str(e)}")

        # ÂÖúÂ∫ïÔºö‰ªçÊó†Ê≥ïÊèêÂèñÊñáÊú¨Êó∂ÔºåËøîÂõûÂç†‰ΩçÊñáÊú¨ÔºåÈÅøÂÖçAIÊµÅÁ®ãÁõ¥Êé•Â§±Ë¥•
        if not extracted_text:
            extracted_text = f"(No extractable text from file: {filename}. Try preview/download.)"

        return extracted_text

    def classify_industry(self, text: str) -> Dict[str, Any]:
        """‰ΩøÁî®ÁúüÊ≠£ÁöÑAIÂØπÊñáÊ°£ËøõË°åË°å‰∏öÂàÜÁ±ª"""
        if not text:
            return {"category": "Êú™ÂàÜÁ±ª", "confidence": 0.0, "keywords": []}

        # ÊñπÊ≥ï1: ‰ΩøÁî®BERTÊ®°ÂûãÂàÜÁ±ªÔºàÂ¶ÇÊûúÂèØÁî®Ôºâ
        if self.text_classifier and len(text) > 10:
            try:
                # Êà™ÂèñÊñáÊú¨Ââç512‰∏™Â≠óÁ¨¶ÔºàBERTÈôêÂà∂Ôºâ
                text_sample = text[:512]
                result = self.text_classifier(text_sample)

                # Â∞ÜBERTÁªìÊûúÊò†Â∞ÑÂà∞Êàë‰ª¨ÁöÑË°å‰∏öÂàÜÁ±ª
                bert_label = result[0]['label']
                bert_confidence = result[0]['score']

                # ÁÆÄÂçïÁöÑÊ†áÁ≠æÊò†Â∞ÑÔºàÂèØ‰ª•Ê†πÊçÆÈúÄË¶ÅÊâ©Â±ïÔºâ
                label_mapping = {
                    'LABEL_0': 'ÁßçÊ§ç‰∏ö',
                    'LABEL_1': 'ÁïúÁâß‰∏ö',
                    'LABEL_2': 'ÂÜúËµÑ‰∏éÂúüÂ£§',
                    'LABEL_3': 'ÂÜú‰∏öÈáëËûç',
                    'LABEL_4': '‰æõÂ∫îÈìæ‰∏é‰ªìÂÇ®',
                    'LABEL_5': 'Ê∞îÂÄô‰∏éÈÅ•ÊÑü',
                    'LABEL_6': 'ÂÜú‰∏öÁâ©ËÅîÁΩë'
                }

                mapped_category = label_mapping.get(bert_label, 'Êú™ÂàÜÁ±ª')

                if mapped_category != 'Êú™ÂàÜÁ±ª':
                    return {
                        "category": mapped_category,
                        "confidence": bert_confidence,
                        "keywords": self._extract_keywords_from_text(text),
                        "method": "BERT"
                    }
            except Exception as e:
                # Suppress noisy toast; fallback methods will be tried below
                pass

        # ÊñπÊ≥ï2: ‰ΩøÁî®Êú∫Âô®Â≠¶‰π†ÂàÜÁ±ªÂô®ÔºàÂ¶ÇÊûúÂèØÁî®‰∏îÂ∑≤ËÆ≠ÁªÉÔºâ
        if self.ml_classifier and self.ml_trained and len(text) > 20:
            try:
                X = [text]
                y_pred = self.ml_classifier.predict(X)
                y_proba = self.ml_classifier.predict_proba(X)

                categories = list(self.industry_keywords.keys())
                predicted_category = categories[y_pred[0]]
                confidence = y_proba[0].max()

                return {
                    "category": predicted_category,
                    "confidence": confidence,
                    "keywords": self._extract_keywords_from_text(text),
                    "method": "ML"
                }
            except Exception as e:
                # Suppress noisy toast; fallback to rules
                pass

        # ÊñπÊ≥ï3: Êô∫ËÉΩÂÖ≥ÈîÆËØçÂåπÈÖçÔºàÊîπËøõÁâàÔºâ
        words = jieba.lcut(text)
        category_scores = {}
        matched_keywords = {}

        for category, keywords in self.industry_keywords.items():
            score = 0
            matched = []

            # Âü∫Á°ÄÂÖ≥ÈîÆËØçÂåπÈÖç
            for keyword in keywords:
                if keyword in text:
                    score += 1
                    matched.append(keyword)

            # Âêå‰πâËØçÂíåÁõ∏‰ººËØçÂåπÈÖç
            synonyms = self._get_synonyms(category)
            for synonym in synonyms:
                if synonym in text:
                    score += 0.5
                    matched.append(synonym)

            # ËØçÈ¢ëÊùÉÈáç
            for keyword in keywords:
                count = text.count(keyword)
                if count > 1:
                    score += count * 0.2

            category_scores[category] = score
            matched_keywords[category] = matched

        if category_scores and max(category_scores.values()) > 0:
            best_category = max(category_scores, key=category_scores.get)
            max_score = category_scores[best_category]

            # ÊîπËøõÁöÑÁΩÆ‰ø°Â∫¶ËÆ°ÁÆó
            total_keywords = len(self.industry_keywords[best_category])
            confidence = min(max_score / (total_keywords * 1.5), 1.0)

            # Â¶ÇÊûúÁΩÆ‰ø°Â∫¶Â§™‰ΩéÔºåÊ†áËÆ∞‰∏∫Êú™ÂàÜÁ±ª
            if confidence < 0.1:
                return {"category": "Êú™ÂàÜÁ±ª", "confidence": 0.0, "keywords": [], "method": "ÂÖ≥ÈîÆËØçÂåπÈÖç"}

            return {
                "category": best_category,
                "confidence": confidence,
                "keywords": matched_keywords[best_category],
                "method": "Êô∫ËÉΩÂÖ≥ÈîÆËØçÂåπÈÖç"
            }

        return {"category": "Êú™ÂàÜÁ±ª", "confidence": 0.0, "keywords": [], "method": "Êó†ÂåπÈÖç"}

    def _get_synonyms(self, category: str) -> List[str]:
        """Ëé∑ÂèñË°å‰∏öÂàÜÁ±ªÁöÑÂêå‰πâËØç"""
        synonyms_map = {
            "ÁßçÊ§ç‰∏ö": ["ÁßçÊ§ç", "ËÄï‰Ωú", "ËÇ≤Áßß", "ÁßªÊ†Ω", "ÂØÜÊ§ç", "ÁóÖËô´ÂÆ≥", "ÊñΩËÇ•", "ÁÅåÊ∫â", "Áî∞Èó¥ÁÆ°ÁêÜ", "ÁéâÁ±≥", "È´òÁ≤±",
                       "Â∞èÁ±≥", "Êú®ËñØ", "Ëä±Áîü", "ËäùÈ∫ª", "Ê£âËä±", "ÂèØÂèØ", "ÂíñÂï°"],
            "ÁïúÁâß‰∏ö": ["ÂÖªÊÆñ", "È•≤ÂñÇ", "ÂÖçÁñ´", "Èò≤Áñ´", "ÁπÅËÇ≤", "Êñ≠Â•∂", "Âá∫Ê†è", "Â≠òÊ†è", "Â¢ûÈáç"],
            "ÂÜúËµÑ‰∏éÂúüÂ£§": ["ÈÖçÊñπÊñΩËÇ•", "ÂúüÂ£§ÊîπËâØ", "ÊñΩÁî®Èáè", "ÊúâÊú∫ËÇ•", "ÂæÆÈáèÂÖÉÁ¥†", "ÂúüÂ£§ÂÖªÂàÜ"],
            "ÂÜú‰∏öÈáëËûç": ["Ë¥¥Áé∞", "Êéà‰ø°", "‰øùË¥π", "Ëµî‰ªò", "Êâø‰øù", "È£éÊéß", "‰øùÂçï"],
            "‰æõÂ∫îÈìæ‰∏é‰ªìÂÇ®": ["ÂÜ∑ÈìæËøêËæì", "ÊçüËÄóÁéá", "ÊâπÊ¨°ËøΩÊ∫Ø", "Â∫ìÂÆπ", "Âë®ËΩ¨Áéá", "ÂàÜÊã£"],
            "Ê∞îÂÄô‰∏éÈÅ•ÊÑü": ["ÈôçÈõ®", "Ê∞îÊ∏©", "ÁßØÊ∏©", "Âπ≤Êó±ÊåáÊï∞", "NDVI", "EVI", "ÈÅ•ÊÑü", "Ê≤ôÊº†ËùóËô´", "ËçâÂú∞Ë¥™Â§úËõæ"],
            "ÂÜú‰∏öÁâ©ËÅîÁΩë": ["Âê´Ê∞¥Áéá", "EC", "Êª¥ÁÅå", "Âñ∑ÁÅå", "ÈòÄÈó®", "ÈòàÂÄº", "Êä•Ë≠¶"]
        }
        return synonyms_map.get(category, [])

    def init_pretrained_classifier(self):
        """ÂàùÂßãÂåñÈ¢ÑËÆ≠ÁªÉÁöÑÂàÜÁ±ªÂô®"""
        if not self.ml_classifier:
            return False

        try:
            # ‰ΩøÁî®È¢ÑÂÆö‰πâÁöÑÂÖ≥ÈîÆËØç‰Ωú‰∏∫ÁâπÂæÅËøõË°åËÆ≠ÁªÉ
            X_train = []
            y_train = []

            # ‰∏∫ÊØè‰∏™Ë°å‰∏öÁ±ªÂà´ÂàõÂª∫ËÆ≠ÁªÉÊ†∑Êú¨
            for category, keywords in self.industry_keywords.items():
                # ‰∏∫ÊØè‰∏™ÂÖ≥ÈîÆËØçÂàõÂª∫ËÆ≠ÁªÉÊ†∑Êú¨
                for keyword in keywords:
                    # ÂàõÂª∫ÂåÖÂê´ÂÖ≥ÈîÆËØçÁöÑÊ†∑Êú¨ÊñáÊú¨
                    sample_text = f"ËøôÊòØ‰∏Ä‰∏™ÂÖ≥‰∫é{keyword}ÁöÑÊñáÊ°£ÔºåÊ∂âÂèä{category}È¢ÜÂüüÁöÑÂÜÖÂÆπ„ÄÇ"
                    X_train.append(sample_text)
                    y_train.append(category)

                # Ê∑ªÂä†Âêå‰πâËØçÊ†∑Êú¨
                synonyms = self._get_synonyms(category)
                for synonym in synonyms:
                    sample_text = f"ËøôÊòØ‰∏Ä‰∏™ÂÖ≥‰∫é{synonym}ÁöÑÊñáÊ°£ÔºåÊ∂âÂèä{category}È¢ÜÂüüÁöÑÂÜÖÂÆπ„ÄÇ"
                    X_train.append(sample_text)
                    y_train.append(category)

            # ËÆ≠ÁªÉÂàÜÁ±ªÂô®
            if len(X_train) > 0:
                self.ml_classifier.fit(X_train, y_train)
                self.ml_trained = True
                return True
            else:
                return False

        except Exception as e:
            st.error(f"ÂàùÂßãÂåñÈ¢ÑËÆ≠ÁªÉÂàÜÁ±ªÂô®Â§±Ë¥•: {str(e)}")
            return False

    def _extract_keywords_from_text(self, text: str) -> List[str]:
        """‰ªéÊñáÊú¨‰∏≠ÊèêÂèñÂÖ≥ÈîÆËØç"""
        try:
            # ‰ΩøÁî®jiebaÁöÑTF-IDFÊèêÂèñÂÖ≥ÈîÆËØç
            keywords = jieba.analyse.extract_tags(text, topK=10, withWeight=False)
            return keywords
        except:
            # ÁÆÄÂçïÁöÑÂÖ≥ÈîÆËØçÊèêÂèñ
            words = jieba.lcut(text)
            word_count = Counter(words)
            stop_words = {'ÁöÑ', '‰∫Ü', 'Âú®', 'ÊòØ', 'Êàë', 'Êúâ', 'Âíå', 'Â∞±', '‰∏ç', '‰∫∫', 'ÈÉΩ', '‰∏Ä', '‰∏Ä‰∏™', '‰∏ä', '‰πü',
                          'Âæà', 'Âà∞', 'ËØ¥', 'Ë¶Å', 'Âéª', '‰Ω†', '‰ºö', 'ÁùÄ', 'Ê≤°Êúâ', 'Áúã', 'Â•Ω', 'Ëá™Â∑±', 'Ëøô'}
            filtered_words = {word: count for word, count in word_count.items()
                              if len(word) > 1 and word not in stop_words and count > 1}
            return list(dict(sorted(filtered_words.items(), key=lambda x: x[1], reverse=True)[:10]).keys())

    def extract_key_phrases(self, text: str, top_k: int = 10) -> List[str]:
        """ÊèêÂèñÂÖ≥ÈîÆÁü≠ËØ≠"""
        if not text:
            return []

        try:
            # ‰ΩøÁî®jiebaÁöÑTF-IDFÊèêÂèñÂÖ≥ÈîÆËØç
            keywords = jieba.analyse.extract_tags(text, topK=top_k, withWeight=False)
            return keywords
        except:
            # ÁÆÄÂçïÁöÑÂÖ≥ÈîÆËØçÊèêÂèñ
            words = jieba.lcut(text)
            word_count = Counter(words)
            # ËøáÊª§ÊéâÂçïÂ≠óÁ¨¶ÂíåÂ∏∏ËßÅÂÅúÁî®ËØç
            stop_words = {'ÁöÑ', '‰∫Ü', 'Âú®', 'ÊòØ', 'Êàë', 'Êúâ', 'Âíå', 'Â∞±', '‰∏ç', '‰∫∫', 'ÈÉΩ', '‰∏Ä', '‰∏Ä‰∏™', '‰∏ä', '‰πü',
                          'Âæà', 'Âà∞', 'ËØ¥', 'Ë¶Å', 'Âéª', '‰Ω†', '‰ºö', 'ÁùÄ', 'Ê≤°Êúâ', 'Áúã', 'Â•Ω', 'Ëá™Â∑±', 'Ëøô'}
            filtered_words = {word: count for word, count in word_count.items()
                              if len(word) > 1 and word not in stop_words and count > 1}
            return list(dict(sorted(filtered_words.items(), key=lambda x: x[1], reverse=True)[:top_k]).keys())

    def generate_summary(self, text: str, max_length: int = 200) -> str:
        """Generate document summary (model first, fallback to rules)."""
        if not text:
            return "Unable to generate summary"

        # ÊñπÊ≥ï1: ‰ΩøÁî®T5Ê®°ÂûãÁîüÊàêÊëòË¶ÅÔºàÂ¶ÇÊûúÂèØÁî®Ôºâ
        if self.summarizer and len(text) > 50:
            try:
                # Êà™ÂèñÊñáÊú¨Ââç1024‰∏™Â≠óÁ¨¶ÔºàT5ÈôêÂà∂Ôºâ
                text_sample = text[:1024]
                summary_result = self.summarizer(
                    text_sample,
                    max_length=min(max_length, 150),
                    min_length=30,
                    do_sample=False
                )

                if summary_result and len(summary_result) > 0:
                    ai_summary = summary_result[0]['summary_text']
                    return f"ü§ñ AI Summary: {ai_summary}"
            except Exception as e:
                st.warning(f"T5 summarization failed: {str(e)}")

        # ÊñπÊ≥ï2: ‰ΩøÁî®OpenAI GPTÔºàÂ¶ÇÊûúÂèØÁî®Ôºâ
        if OPENAI_AVAILABLE and len(text) > 100:
            try:
                # ËøôÈáåÈúÄË¶ÅOpenAI APIÂØÜÈí•
                # ÊöÇÊó∂Ë∑≥ËøáÔºåÂõ†‰∏∫ÈúÄË¶ÅAPIÂØÜÈí•
                pass
            except Exception as e:
                st.warning(f"OpenAI summarization failed: {str(e)}")

        # ÊñπÊ≥ï3: Êô∫ËÉΩÂè•Â≠êÈÄâÊã©ÔºàÊîπËøõÁöÑËßÑÂàôÊñπÊ≥ïÔºâ
        try:
            # ‰ΩøÁî®Êõ¥Êô∫ËÉΩÁöÑÂè•Â≠êÈÄâÊã©
            sentences = re.split(r'[„ÄÇÔºÅÔºü.!?]', text)
            sentences = [s.strip() for s in sentences if s.strip() and len(s) > 10]

            if len(sentences) <= 2:
                return text[:max_length] + "..." if len(text) > max_length else text

            # ÈÄâÊã©ÊúÄÈáçË¶ÅÁöÑÂè•Â≠êÔºàÂü∫‰∫éÈïøÂ∫¶ÂíåÂÖ≥ÈîÆËØçÔºâ
            scored_sentences = []
            for i, sentence in enumerate(sentences):
                score = len(sentence)  # Âü∫Á°ÄÂàÜÊï∞ÔºöÂè•Â≠êÈïøÂ∫¶

                # ÂÖ≥ÈîÆËØçÂä†ÂàÜ
                important_words = ['ÈáçË¶Å', 'ÂÖ≥ÈîÆ', '‰∏ªË¶Å', 'Ê†∏ÂøÉ', 'ÊÄªÁªì', 'ÁªìËÆ∫', 'ÁªìÊûú', 'ÂèëÁé∞']
                for word in important_words:
                    if word in sentence:
                        score += 20

                # ‰ΩçÁΩÆÂä†ÂàÜÔºàÂºÄÂ§¥ÂíåÁªìÂ∞æÁöÑÂè•Â≠êÊõ¥ÈáçË¶ÅÔºâ
                if i < 2 or i >= len(sentences) - 2:
                    score += 10

                scored_sentences.append((score, sentence))

            # ÈÄâÊã©ÂæóÂàÜÊúÄÈ´òÁöÑ2-3‰∏™Âè•Â≠ê
            scored_sentences.sort(reverse=True)
            selected_sentences = [s[1] for s in scored_sentences[:3]]

            summary = '„ÄÇ'.join(selected_sentences)
            if len(summary) > max_length:
                summary = summary[:max_length] + "..."

            return f"üìù Smart summary: {summary}"
        except:
            # ÊñπÊ≥ï4: ÁÆÄÂçïÊà™ÂèñÔºàÊúÄÂêéÂ§áÁî®Ôºâ
            return text[:max_length] + "..." if len(text) > max_length else text

    def analyze_file_with_ai(self, file_id: int) -> Dict[str, Any]:
        """‰ΩøÁî®AIÂàÜÊûêÊñá‰ª∂"""
        # ÊèêÂèñÊñáÊú¨
        extracted_text = self.extract_text_from_file(file_id)

        if not extracted_text:
            return {"success": False, "error": "Unable to extract text"}

        # Ë°å‰∏öÂàÜÁ±ª
        classification = self.classify_industry(extracted_text)
        if isinstance(classification, dict) and 'category' in classification:
            classification['category'] = self._to_english_category(classification['category'])

        # ÊèêÂèñÂÖ≥ÈîÆÁü≠ËØ≠
        key_phrases = self.extract_key_phrases(extracted_text)

        # ÁîüÊàêÊëòË¶Å
        summary = self.generate_summary(extracted_text)

        # ‰øùÂ≠òÂàÜÊûêÁªìÊûúÂà∞Êï∞ÊçÆÂ∫ì
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            INSERT INTO ai_analysis (file_id, analysis_type, industry_category, extracted_text, key_phrases, summary, confidence_score, method)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (file_id, "full_analysis", classification["category"],
              extracted_text[:1000], json.dumps(key_phrases, ensure_ascii=False),
              summary, classification["confidence"], classification.get("method", "Unknown")))

        conn.commit()
        conn.close()

        return {
            "success": True,
            "extracted_text": extracted_text,
            "classification": classification,
            "key_phrases": key_phrases,
            "summary": summary
        }

    def get_ai_analysis(self, file_id: int) -> Optional[Dict[str, Any]]:
        """Ëé∑ÂèñÊñá‰ª∂ÁöÑAIÂàÜÊûêÁªìÊûú"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            SELECT analysis_type, industry_category, extracted_text, key_phrases, summary, confidence_score, method, analysis_time
            FROM ai_analysis WHERE file_id = ? ORDER BY analysis_time DESC LIMIT 1
        ''', (file_id,))
        result = cursor.fetchone()
        conn.close()

        if result:
            analysis_type, industry_category, extracted_text, key_phrases, summary, confidence_score, method, analysis_time = result
            return {
                "analysis_type": analysis_type,
                "industry_category": industry_category,
                "extracted_text": extracted_text,
                "key_phrases": json.loads(key_phrases) if key_phrases else [],
                "summary": summary,
                "confidence_score": confidence_score,
                "method": method or "Unknown",
                "analysis_time": analysis_time
            }
        return None

    def create_industry_folder(self, category: str) -> int:
        """‰∏∫Ë°å‰∏öÂàÜÁ±ªÂàõÂª∫Êñá‰ª∂Â§π"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # Ê£ÄÊü•Êñá‰ª∂Â§πÊòØÂê¶Â∑≤Â≠òÂú®ÔºàËã±ÊñáÂëΩÂêçÔºâ
        eng_category = self._to_english_category(category)
        cursor.execute('SELECT id FROM folders WHERE folder_name = ?', (f"AI_{eng_category}",))
        result = cursor.fetchone()

        if result:
            folder_id = result[0]
        else:
            cursor.execute('''
                INSERT INTO folders (folder_name, parent_folder_id)
                VALUES (?, ?)
            ''', (f"AI_{eng_category}", None))
            folder_id = cursor.lastrowid

        conn.commit()
        conn.close()
        return folder_id

    def move_file_to_industry_folder(self, file_id: int, category: str) -> bool:
        """Â∞ÜÊñá‰ª∂ÁßªÂä®Âà∞Ë°å‰∏öÂàÜÁ±ªÊñá‰ª∂Â§π"""
        try:
            folder_id = self.create_industry_folder(category)

            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('UPDATE files SET folder_id = ? WHERE id = ?', (folder_id, file_id))
            conn.commit()
            conn.close()
            return True
        except:
            return False

    # ==================== Âü∫Á°ÄÊñá‰ª∂ÁÆ°ÁêÜÂäüËÉΩ ====================

    def rename_file(self, file_id: int, new_filename: str) -> Dict[str, Any]:
        """ÈáçÂëΩÂêçÊñá‰ª∂"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # Ê£ÄÊü•Êñ∞Êñá‰ª∂ÂêçÊòØÂê¶Â∑≤Â≠òÂú®
            cursor.execute('SELECT id FROM files WHERE filename = ? AND id != ?', (new_filename, file_id))
            if cursor.fetchone():
                conn.close()
                return {"success": False, "error": "Êñá‰ª∂ÂêçÂ∑≤Â≠òÂú®"}

            # Êõ¥Êñ∞Êñá‰ª∂Âêç
            cursor.execute('UPDATE files SET filename = ? WHERE id = ?', (new_filename, file_id))
            conn.commit()
            conn.close()

            return {"success": True, "new_filename": new_filename}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def delete_file(self, file_id: int) -> Dict[str, Any]:
        """Âà†Èô§Êñá‰ª∂"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # Ëé∑ÂèñÊñá‰ª∂Ë∑ØÂæÑ
            cursor.execute('SELECT file_path FROM files WHERE id = ?', (file_id,))
            result = cursor.fetchone()

            if result:
                file_path = result[0]

                # Âà†Èô§Áâ©ÁêÜÊñá‰ª∂
                if os.path.exists(file_path):
                    os.remove(file_path)

                # Âà†Èô§Êï∞ÊçÆÂ∫ìËÆ∞ÂΩï
                cursor.execute('DELETE FROM files WHERE id = ?', (file_id,))

                # Âà†Èô§AIÂàÜÊûêËÆ∞ÂΩï
                cursor.execute('DELETE FROM ai_analysis WHERE file_id = ?', (file_id,))

                conn.commit()
                conn.close()

                return {"success": True}
            else:
                conn.close()
                return {"success": False, "error": "Êñá‰ª∂‰∏çÂ≠òÂú®"}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def rename_folder(self, folder_id: int, new_folder_name: str) -> Dict[str, Any]:
        """ÈáçÂëΩÂêçÊñá‰ª∂Â§π"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # Ê£ÄÊü•Êñ∞Êñá‰ª∂Â§πÂêçÊòØÂê¶Â∑≤Â≠òÂú®
            cursor.execute('SELECT id FROM folders WHERE folder_name = ? AND id != ?', (new_folder_name, folder_id))
            if cursor.fetchone():
                conn.close()
                return {"success": False, "error": "Êñá‰ª∂Â§πÂêçÂ∑≤Â≠òÂú®"}

            # Êõ¥Êñ∞Êñá‰ª∂Â§πÂêç
            cursor.execute('UPDATE folders SET folder_name = ? WHERE id = ?', (new_folder_name, folder_id))
            conn.commit()
            conn.close()

            return {"success": True, "new_folder_name": new_folder_name}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def delete_folder(self, folder_id: int) -> Dict[str, Any]:
        """Âà†Èô§Êñá‰ª∂Â§π"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # Ê£ÄÊü•Êñá‰ª∂Â§πÊòØÂê¶‰∏∫Á©∫
            cursor.execute('SELECT COUNT(*) FROM files WHERE folder_id = ?', (folder_id,))
            file_count = cursor.fetchone()[0]

            if file_count > 0:
                conn.close()
                return {"success": False, "error": f"Êñá‰ª∂Â§π‰∏ç‰∏∫Á©∫ÔºåÂåÖÂê´ {file_count} ‰∏™Êñá‰ª∂"}

            # Ê£ÄÊü•ÊòØÂê¶ÊúâÂ≠êÊñá‰ª∂Â§π
            cursor.execute('SELECT COUNT(*) FROM folders WHERE parent_folder_id = ?', (folder_id,))
            subfolder_count = cursor.fetchone()[0]

            if subfolder_count > 0:
                conn.close()
                return {"success": False, "error": f"Êñá‰ª∂Â§πÂåÖÂê´ {subfolder_count} ‰∏™Â≠êÊñá‰ª∂Â§π"}

            # Âà†Èô§Êñá‰ª∂Â§π
            cursor.execute('DELETE FROM folders WHERE id = ?', (folder_id,))
            conn.commit()
            conn.close()

            return {"success": True}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def get_folders(self, parent_folder_id: Optional[int] = None) -> List[Dict[str, Any]]:
        """Ëé∑ÂèñÊñá‰ª∂Â§πÂàóË°®"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        if parent_folder_id is None:
            cursor.execute('''
                SELECT id, folder_name, created_time, 
                       (SELECT COUNT(*) FROM files WHERE folder_id = folders.id) as file_count
                FROM folders 
                WHERE parent_folder_id IS NULL
                ORDER BY created_time DESC
            ''')
        else:
            cursor.execute('''
                SELECT id, folder_name, created_time,
                       (SELECT COUNT(*) FROM files WHERE folder_id = folders.id) as file_count
                FROM folders 
                WHERE parent_folder_id = ?
                ORDER BY created_time DESC
            ''', (parent_folder_id,))

        folders = []
        for row in cursor.fetchall():
            folders.append({
                "id": row[0],
                "folder_name": row[1],
                "created_time": row[2],
                "file_count": row[3]
            })

        conn.close()
        return folders

    def sync_cached_files(self) -> Dict[str, Any]:
        """ÂêåÊ≠•ÁºìÂ≠òÊñá‰ª∂Âà∞‰∫ëÁ´Ø"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # Ëé∑ÂèñÊâÄÊúâÂ∑≤ÁºìÂ≠òÁöÑÊñá‰ª∂
            cursor.execute('''
                SELECT id, filename, file_path, last_modified
                FROM files 
                WHERE is_cached = TRUE
            ''')

            cached_files = cursor.fetchall()
            synced_count = 0

            for file_id, filename, file_path, last_modified in cached_files:
                # Ê£ÄÊü•Êñá‰ª∂ÊòØÂê¶‰ªçÁÑ∂Â≠òÂú®
                if os.path.exists(file_path):
                    # Êõ¥Êñ∞ÊúÄÂêé‰øÆÊîπÊó∂Èó¥
                    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    cursor.execute('''
                        UPDATE files 
                        SET last_modified = ? 
                        WHERE id = ?
                    ''', (current_time, file_id))
                    synced_count += 1

            conn.commit()
            conn.close()

            return {
                "success": True,
                "synced_count": synced_count,
                "message": f"ÊàêÂäüÂêåÊ≠• {synced_count} ‰∏™ÁºìÂ≠òÊñá‰ª∂"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}


# ÂàùÂßãÂåñ‰∫ëÂ≠òÂÇ®ÁÆ°ÁêÜÂô®
if 'storage_manager' not in st.session_state:
    st.session_state.storage_manager = CloudStorageManager()

storage_manager = st.session_state.storage_manager

# ‰æßËæπÊ†è
with st.sidebar:
    st.markdown("### üåæ Agribusiness Expert AI Cloud")
    st.markdown("---")

    # Âø´ÈÄüÊìç‰Ωú
    st.markdown("### ‚ö° Quick Actions")

    # Êñá‰ª∂Â§πÁÆ°ÁêÜ
    st.markdown("### üìÅ Folder Management")

    # ÂàõÂª∫Êñá‰ª∂Â§π
    with st.form("create_folder_form"):
        folder_name = st.text_input("üìÅ New Folder", placeholder="Enter folder name")
        if st.form_submit_button("Create", width='stretch'):
            if folder_name:
                result = storage_manager.create_folder(folder_name)
                if result["success"]:
                    st.success(f"‚úÖ Folder '{folder_name}' created successfully!")
                else:
                    st.error(f"‚ùå Creation failed: {result['error']}")
            else:
                st.warning("Please enter folder name")

    # Êñá‰ª∂Â§πÂàóË°®
    folders = storage_manager.get_folders()
    if folders:
        st.markdown("#### Existing Folders")
        for folder in folders:
            col1, col2, col3 = st.columns([3, 1, 1])
            with col1:
                st.write(f"üìÅ {folder['folder_name']}")
                st.caption(f"Files: {folder['file_count']} | Created: {folder['created_time']}")
            with col2:
                # ÈáçÂëΩÂêçÊñá‰ª∂Â§π
                with st.popover("‚úèÔ∏è", help="Rename folder"):
                    new_name = st.text_input("New Name", value=folder['folder_name'],
                                             key=f"folder_rename_{folder['id']}")
                    if st.button("‚úÖ Confirm", key=f"folder_rename_confirm_{folder['id']}"):
                        result = storage_manager.rename_folder(folder['id'], new_name)
                        if result["success"]:
                            st.success("Rename successful!")
                            st.rerun()
                        else:
                            st.error(f"Rename failed: {result['error']}")
            with col3:
                # Âà†Èô§Êñá‰ª∂Â§π
                if st.button("üóëÔ∏è", key=f"folder_delete_{folder['id']}", help="Delete folder"):
                    result = storage_manager.delete_folder(folder['id'])
                    if result["success"]:
                        st.success("Folder deleted!")
                        st.rerun()
                    else:
                        st.error(f"Delete failed: {result['error']}")

    # ÂêåÊ≠•ÂäüËÉΩ
    st.markdown("---")
    if st.button("üîÑ Sync Cache", width='stretch', help="Sync all cached files"):
        result = storage_manager.sync_cached_files()
        if result["success"]:
            st.success(result["message"])
        else:
            st.error(f"Sync failed: {result['error']}")

    st.markdown("---")

    # AgribusinessÂ∑•ÂÖ∑‰∏éAIÂäüËÉΩÂå∫Âüü
    st.markdown("### üåæ Agribusiness Tools & AI")
    with st.expander("‚òÅÔ∏è Weather & Climate (Open-Meteo)", expanded=False):
        colw1, colw2 = st.columns(2)
        with colw1:
            lat = st.number_input("Latitude", value=0.0, step=0.1)
        with colw2:
            lon = st.number_input("Longitude", value=20.0, step=0.1)
        if st.button("Fetch 7-Day Climate Summary", use_container_width=True):
            with st.spinner("Fetching weather data..."):
                res = storage_manager.fetch_weather_summary(lat, lon)
                if res.get("success"):
                    ws = res["weather"]["summary"]
                    st.success("Weather updated")
                    st.write({
                        "7d total rainfall (mm)": ws.get("7d_total_rain_mm"),
                        "Avg Tmax (¬∞C)": ws.get("avg_tmax"),
                        "Avg Tmin (¬∞C)": ws.get("avg_tmin")
                    })
                else:
                    st.error(f"Weather fetch failed: {res.get('error')}")

    with st.expander("üõ∞Ô∏è Remote Sensing (NDVI/EVI)", expanded=False):
        colr1, colr2, colr3 = st.columns(3)
        with colr1:
            rs_lat = st.number_input("Latitude", value=0.0, step=0.1, key="rs_lat")
        with colr2:
            rs_lon = st.number_input("Longitude", value=20.0, step=0.1, key="rs_lon")
        with colr3:
            rs_days = st.slider("Days", min_value=7, max_value=60, value=30, step=1, key="rs_days")
        if st.button("Generate NDVI/EVI Timeseries", use_container_width=True):
            with st.spinner("Generating NDVI/EVI (stub)..."):
                res = storage_manager.compute_remote_sensing_stub(rs_lat, rs_lon, rs_days)
                if res.get("success"):
                    rs = res["remote_sensing"]
                    st.success("Generated")
                    if rs.get("dates") and rs.get("ndvi"):
                        st.markdown("**NDVI**")
                        ndvi_df = pd.DataFrame({"date": rs["dates"], "NDVI": rs["ndvi"]}).set_index("date")
                        st.line_chart(ndvi_df)
                    if rs.get("dates") and rs.get("evi"):
                        st.markdown("**EVI**")
                        evi_df = pd.DataFrame({"date": rs["dates"], "EVI": rs["evi"]}).set_index("date")
                        st.line_chart(evi_df)
                else:
                    st.error(f"Remote sensing generation failed: {res.get('error')}")

    with st.expander("üßÆ Agri Quick Calculator", expanded=False):
        st.caption("Quick estimation: total production & profit")
        # ÊÄª‰∫ßÈáè = Èù¢ÁßØ √ó Âçï‰∫ßÔºàËá™Âä®ÂÅöÂ∞ëÈáèÂçï‰ΩçÈÄÇÈÖçÔºâ
        colc1, colc2, colc3 = st.columns(3)
        with colc1:
            area_value = st.number_input("Area value", value=100.0, step=1.0)
            area_unit = st.selectbox("Area unit", ["hectare(ha)", "mu"], index=0)
        with colc2:
            yield_value = st.number_input("Yield value", value=3.0, step=0.1)
            yield_unit = st.selectbox("Yield unit", ["t/ha", "kg/ha", "kg/mu", "jin/mu"], index=0)
        with colc3:
            currency = st.selectbox("Currency", ["USD", "KES", "NGN", "ZAR", "GHS", "XOF", "XAF", "ETB", "TZS"],
                                    index=1)
            price_value = st.number_input("Price (per kg)", value=0.5, step=0.05)
            cost_value = st.number_input("Total cost", value=50000.0, step=1000.0)

        if st.button("Calculate production & profit", use_container_width=True):
            # Âçï‰ΩçÊç¢ÁÆóÂà∞ ÂÖ¨Êñ§/‰∫©
            if yield_unit == "jin/mu":
                yield_kg_per_mu = yield_value * 0.5
            elif yield_unit == "kg/ha":
                yield_kg_per_mu = yield_value / 15.0  # 1 ha ‚âà 15 ‰∫©
            elif yield_unit == "t/ha":
                yield_kg_per_mu = (yield_value * 1000.0) / 15.0
            else:
                yield_kg_per_mu = yield_value

            # Èù¢ÁßØÊç¢ÁÆóÂà∞ ‰∫©
            area_mu = area_value * (15.0 if area_unit == "hectare(ha)" else 1.0)

            total_production_kg = area_mu * yield_kg_per_mu
            revenue = total_production_kg * price_value
            profit = revenue - cost_value
            st.success("Calculated")
            st.write({
                "Total production (kg)": round(total_production_kg, 2),
                f"Revenue ({currency})": round(revenue, 2),
                f"Profit ({currency})": round(profit, 2)
            })

    # AIÊ®°ÂûãÁä∂ÊÄÅ
    with st.expander("üîç AI Model Status", expanded=False):
        col1, col2 = st.columns(2)

        with col1:
            if OCR_AVAILABLE and storage_manager.ocr_reader is not None:
                st.success("‚úÖ OCR Text Recognition")
            elif OCR_AVAILABLE:
                st.warning("üîÑ OCR model loading...")
            else:
                st.error("‚ùå OCR Text Recognition")

            if TRANSFORMERS_AVAILABLE:
                st.success("‚úÖ Deep Learning Model")
            else:
                st.error("‚ùå Deep Learning Model")

        with col2:
            if ML_AVAILABLE:
                st.success("‚úÖ Machine Learning Classification")
            else:
                st.error("‚ùå Machine Learning Classification")

            if OPENAI_AVAILABLE:
                st.success("‚úÖ OpenAI Integration")
            else:
                st.warning("‚ö†Ô∏è OpenAI Integration")

    # AIÂàÜÊûêÊåâÈíÆ
    if st.button("üß† Smart Analysis", width='stretch', help="Perform AI analysis on all files"):
        st.session_state.show_ai_analysis = True
    else:
        st.session_state.show_ai_analysis = False

    # ÈáçÊñ∞ÂàùÂßãÂåñAIÊ®°Âûã
    if st.button("üîÑ Reload AI", width='stretch', help="Reinitialize AI models"):
        with st.spinner("Reloading AI models..."):
            storage_manager.init_ai_models()
            st.success("‚úÖ AI models reloaded successfully!")

    # Ë°å‰∏öÂàÜÁ±ªÊü•Áúã
    if st.button("üìä Industry Classification", width='stretch', help="View files classified by industry"):
        st.session_state.show_industry_view = True
    else:
        st.session_state.show_industry_view = False

    # Êô∫ËÉΩÊä•ÂëäÁîüÊàê
    if st.button("üìà Smart Report", width='stretch', help="Generate smart analysis reports and charts"):
        st.session_state.show_smart_report = True
    else:
        st.session_state.show_smart_report = False

    st.markdown("---")

    # ÊêúÁ¥¢ÂäüËÉΩ
    st.markdown("### üîç Search Files")
    search_query = st.text_input("Search File Name", placeholder="Enter keywords")
    search_type = st.selectbox("File Type", ["All", "image", "application", "text", "video", "audio"])

    if st.button("üîç Search", width='stretch') and search_query:
        file_type = None if search_type == "All" else search_type
        search_results = storage_manager.search_files(search_query, file_type)
        st.session_state.search_results = search_results
        st.session_state.show_search = True
    else:
        st.session_state.show_search = False

# ‰∏ªÁïåÈù¢
st.title("üåæ Agribusiness Expert AI Cloud")
st.markdown("Built for agribusiness: document management + KPIs + climate/remote sensing insights")

# Êñá‰ª∂‰∏ä‰º†Âå∫Âüü
st.markdown("### üì§ File Upload")

# ‰∏ä‰º†Ê®°ÂºèÈÄâÊã©
upload_mode = st.radio(
    "Select Upload Mode",
    ["Normal Upload", "Resume Upload"],
    horizontal=True,
    help="Resume upload supports continuing after network interruption"
)

# ÈÄâÊã©‰∏ä‰º†Êñá‰ª∂Â§π
folders = storage_manager.get_folders()
folder_options = ["Root Directory"] + [f["folder_name"] for f in folders]
selected_folder = st.selectbox("Select Upload Folder", folder_options, help="Choose the folder to upload files to")

# Ëé∑ÂèñÈÄâ‰∏≠ÁöÑÊñá‰ª∂Â§πID
target_folder_id = None
if selected_folder != "Root Directory":
    for folder in folders:
        if folder["folder_name"] == selected_folder:
            target_folder_id = folder["id"]
            break

uploaded_files = st.file_uploader(
    "Choose Files to Upload",
    type=["xlsx", "xls", "csv", "pdf", "png", "jpg", "jpeg", "gif", "bmp", "txt", "doc", "docx"],
    accept_multiple_files=True,
    help="Supports Excel, PDF, Images, CSV and other formats"
)

if uploaded_files:
    for uploaded_file in uploaded_files:
        col1, col2 = st.columns([3, 1])

        with col1:
            st.write(f"üìÑ {uploaded_file.name} ({storage_manager.format_file_size(len(uploaded_file.getbuffer()))})")

        with col2:
            if upload_mode == "Normal Upload":
                if st.button(f"üì§ Upload", key=f"upload_{uploaded_file.name}"):
                    with st.spinner(f"Uploading {uploaded_file.name}..."):
                        result = storage_manager.upload_file(uploaded_file, target_folder_id)
                        if result["success"]:
                            folder_name = selected_folder if selected_folder != "Root Directory" else "Root Directory"
                            st.success(f"‚úÖ {uploaded_file.name} uploaded to {folder_name}!")
                        else:
                            st.error(f"‚ùå Upload failed: {result['error']}")
            else:
                if st.button(f"üîÑ Resume Upload", key=f"resume_upload_{uploaded_file.name}"):
                    with st.spinner(f"Resume uploading {uploaded_file.name}..."):
                        result = storage_manager.upload_file_with_resume(uploaded_file, target_folder_id)
                        if result["success"]:
                            folder_name = selected_folder if selected_folder != "Root Directory" else "Root Directory"
                            st.success(f"‚úÖ {uploaded_file.name} resume uploaded to {folder_name}!")
                        else:
                            st.error(f"‚ùå Resume upload failed: {result['error']}")

# ‰∏ä‰º†ËøõÂ∫¶ÊòæÁ§∫
progress_list = storage_manager.get_upload_progress()
if progress_list:
    st.markdown("### üîÑ Upload Progress")
    for progress in progress_list:
        col1, col2, col3 = st.columns([2, 1, 1])

        with col1:
            st.write(f"üìÑ {progress['filename']}")
            st.progress(progress['progress'])
            st.caption(
                f"{storage_manager.format_file_size(progress['uploaded_size'])} / {storage_manager.format_file_size(progress['total_size'])}")

        with col2:
            if st.button("üîÑ ÁªßÁª≠", key=f"resume_{progress['filename']}"):
                result = storage_manager.resume_upload(progress['filename'])
                if result["success"]:
                    st.success("Continue uploading...")
                else:
                    st.error("Unable to continue upload")

        with col3:
            if st.button("‚ùå ÂèñÊ∂à", key=f"cancel_{progress['filename']}"):
                if storage_manager.cancel_upload(progress['filename']):
                    st.success("Upload cancelled")
                    st.rerun()
                else:
                    st.error("Cancel failed")

# Êñá‰ª∂Â§πÂØºËà™
current_folder_id = st.session_state.get('current_folder_id', None)
if current_folder_id is not None:
    # ÊòæÁ§∫ÂΩìÂâçÊñá‰ª∂Â§π‰ø°ÊÅØ
    conn = sqlite3.connect(storage_manager.db_path)
    cursor = conn.cursor()
    cursor.execute('SELECT folder_name FROM folders WHERE id = ?', (current_folder_id,))
    folder_name = cursor.fetchone()
    conn.close()

    if folder_name:
        col1, col2 = st.columns([3, 1])
        with col1:
            st.markdown(f"### üìÅ Current Folder: {folder_name[0]}")
        with col2:
            if st.button("‚¨ÖÔ∏è Back to Root", width='stretch'):
                st.session_state.current_folder_id = None
                st.rerun()

# Ê£ÄÊü•ÊòæÁ§∫Ê®°Âºè
files = []  # Á°Æ‰øùÂêéÁª≠‰ΩøÁî®Êó∂Â∑≤ÂÆö‰πâ
if st.session_state.get('show_ai_analysis', False):
    st.markdown("### ü§ñ AI Smart Analysis")

    # Ëé∑ÂèñÊâÄÊúâÊñá‰ª∂ËøõË°åAIÂàÜÊûê
    all_files = storage_manager.get_files()

    if all_files:
        st.info(f"Analyzing {len(all_files)} files with AI...")

        # ÊâπÈáèAIÂàÜÊûê
        analysis_results = []
        progress_bar = st.progress(0)
        status_text = st.empty()

        for i, file in enumerate(all_files):
            status_text.text(f"Analyzing: {file['filename']}")
            result = storage_manager.analyze_file_with_ai(file['id'])
            analysis_results.append({
                'file': file,
                'analysis': result
            })
            progress_bar.progress((i + 1) / len(all_files))

        progress_bar.empty()
        status_text.empty()

        # ÊòæÁ§∫ÂàÜÊûêÁªìÊûú
        st.success("AI analysis completed!")

        # ÊåâË°å‰∏öÂàÜÁ±ªÊòæÁ§∫
        industry_groups = {}
        for result in analysis_results:
            if result['analysis']['success']:
                category = result['analysis']['classification']['category']
                if category not in industry_groups:
                    industry_groups[category] = []
                industry_groups[category].append(result)

        for category, files in industry_groups.items():
            with st.expander(f"üìä {category} ({len(files)} files)", expanded=True):
                for result in files:
                    file = result['file']
                    analysis = result['analysis']

                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"üìÑ {file['filename']}")
                        st.caption(f"Confidence: {analysis['classification']['confidence']:.2%}")
                        if analysis['summary']:
                            st.info(f"Summary: {analysis['summary']}")
                    with col2:
                        if st.button("üìÅ Classify", key=f"batch_classify_{file['id']}"):
                            if storage_manager.move_file_to_industry_folder(file['id'], category):
                                st.success("Classified!")
                                st.rerun()

    else:
        st.warning("No files to analyze")

elif st.session_state.get('show_industry_view', False):
    st.markdown("### üìä Industry Classification View")

    # Ëé∑ÂèñÊâÄÊúâË°å‰∏öÂàÜÁ±ª
    conn = sqlite3.connect(storage_manager.db_path)
    cursor = conn.cursor()
    cursor.execute('''
        SELECT DISTINCT industry_category, COUNT(*) as file_count
        FROM ai_analysis 
        WHERE industry_category IS NOT NULL
        GROUP BY industry_category
        ORDER BY file_count DESC
    ''')
    categories = cursor.fetchall()
    conn.close()

    if categories:
        for category, count in categories:
            with st.expander(f"üìÅ {category} ({count} files)", expanded=True):
                # Ëé∑ÂèñËØ•ÂàÜÁ±ªÁöÑÊñá‰ª∂
                conn = sqlite3.connect(storage_manager.db_path)
                cursor = conn.cursor()
                cursor.execute('''
                    SELECT f.id, f.filename, f.file_size, f.upload_time, a.confidence_score, a.summary
                    FROM files f
                    JOIN ai_analysis a ON f.id = a.file_id
                    WHERE a.industry_category = ?
                    ORDER BY a.confidence_score DESC
                ''', (category,))
                file_rows = cursor.fetchall()
                conn.close()

                # ËΩ¨Êç¢‰∏∫Â≠óÂÖ∏Ê†ºÂºè‰ª•‰øùÊåÅ‰∏ÄËá¥ÊÄß
                files = []
                for file_id, filename, file_size, upload_time, confidence, summary in file_rows:
                    files.append({
                        "id": file_id,
                        "filename": filename,
                        "file_size": file_size,
                        "upload_time": upload_time,
                        "confidence": confidence,
                        "summary": summary
                    })

                for file in files:
                    col1, col2, col3 = st.columns([3, 1, 1])
                    with col1:
                        st.write(f"üìÑ {file['filename']}")
                        st.caption(f"Uploaded: {file['upload_time']}")
                        if file['summary']:
                            st.info(f"Summary: {file['summary']}")
                    with col2:
                        st.metric("Confidence", f"{file['confidence']:.2%}")
                    with col3:
                        st.metric("File Size", storage_manager.format_file_size(file['file_size']))
    else:
        st.info("No files have been analyzed by AI yet")

# Êñá‰ª∂ÂàóË°®ÊòæÁ§∫
elif st.session_state.get('show_search', False) and 'search_results' in st.session_state:
    st.markdown("### üîç Search Results")
    files = st.session_state.search_results
    st.info(f"üîç Search Results: Found {len(files)} files")
else:
    st.markdown("### üìÅ File List")
    files = storage_manager.get_files(current_folder_id)

    # ÊòæÁ§∫Â≠êÊñá‰ª∂Â§π
    if current_folder_id is None:
        subfolders = storage_manager.get_folders()
    else:
        subfolders = storage_manager.get_folders(current_folder_id)

    if subfolders:
        st.markdown("#### üìÅ Folders")
        for folder in subfolders:
            col1, col2, col3 = st.columns([3, 1, 1])
            with col1:
                if st.button(f"üìÅ {folder['folder_name']} ({folder['file_count']} files)",
                             key=f"enter_folder_{folder['id']}", width='stretch'):
                    st.session_state.current_folder_id = folder['id']
                    st.rerun()
            with col2:
                if st.button("‚úèÔ∏è", key=f"rename_folder_ui_{folder['id']}", help="Rename"):
                    st.session_state[f"rename_folder_{folder['id']}"] = True
            with col3:
                if st.button("üóëÔ∏è", key=f"delete_folder_ui_{folder['id']}", help="Delete"):
                    result = storage_manager.delete_folder(folder['id'])
                    if result["success"]:
                        st.success("Folder deleted!")
                        st.rerun()
                    else:
                        st.error(f"Delete failed: {result['error']}")

        st.markdown("---")

if files:
    # Êñá‰ª∂ÁªüËÆ°
    total_size = sum(file.get('file_size', 0) for file in files)
    cached_count = sum(1 for file in files if file.get('is_cached', False))

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total Files", len(files))
    with col2:
        st.metric("Total Size", storage_manager.format_file_size(total_size))
    with col3:
        st.metric("Cached", f"{cached_count}/{len(files)}")
    with col4:
        st.metric("Cache Rate", f"{cached_count / len(files) * 100:.1f}%")

    st.markdown("---")

    # Êñá‰ª∂ÂàóË°® - ‰ΩøÁî®Âç°ÁâáÂºèÂ∏ÉÂ±Ä
    for file in files:
        with st.container():
            # Êñá‰ª∂Âç°Áâá
            st.markdown(f"""
            <div class="file-card">
                <div style="display: flex; align-items: center; justify-content: space-between;">
                    <div style="display: flex; align-items: center; flex: 1;">
                        <span class="file-icon">{storage_manager.get_file_icon(file.get('file_type', 'unknown'))}</span>
                        <div>
                            <h4 style="margin: 0; color: #1e293b;">{file.get('filename', 'Unknown')}</h4>
                            <p style="margin: 4px 0 0 0; color: #64748b; font-size: 14px;">
                                Type: {file.get('file_type', 'unknown')} | Uploaded: {file.get('upload_time', '')}
                            </p>
                        </div>
                    </div>
                    <div style="display: flex; align-items: center; gap: 16px;">
                        <span style="font-weight: 600; color: #475569;">{storage_manager.format_file_size(file.get('file_size', 0))}</span>
                        <span style="padding: 4px 8px; border-radius: 4px; font-size: 12px; background: {'#dcfce7' if file.get('is_cached', False) else '#dbeafe'}; color: {'#166534' if file.get('is_cached', False) else '#1e40af'};">
                            {'‚úÖ Cached' if file.get('is_cached', False) else '‚òÅÔ∏è Cloud'}
                        </span>
                    </div>
                </div>
            </div>
            """, unsafe_allow_html=True)

            # ‰ΩøÁî®‰∏§ÂàóÂ∏ÉÂ±ÄÔºöÂ∑¶‰æßÊìç‰ΩúÊåâÈíÆÔºåÂè≥‰æßÈ¢ÑËßàÂÜÖÂÆπ
            col_left, col_right = st.columns([1, 1])

            with col_left:
                # È¢ÑËßàÊéßÂà∂
                show_preview = st.checkbox("üëÅÔ∏è Preview File", key=f"preview_{file['id']}",
                                           help="Click to preview file content")

                # Êìç‰ΩúÊåâÈíÆË°å
                col1, col2 = st.columns(2)

                with col1:
                    # AIÂàÜÊûêÊåâÈíÆ
                    if st.button("üß† AI Analysis", key=f"ai_analyze_{file['id']}", help="Use AI to analyze file content",
                                 width='stretch'):
                        with st.spinner("AI is analyzing file..."):
                            result = storage_manager.analyze_file_with_ai(file['id'])
                            if result["success"]:
                                st.success("AI analysis completed!")
                                st.rerun()
                            else:
                                st.error(f"AI analysis failed: {result['error']}")

                    # Êô∫ËÉΩÊä•ÂëäÊåâÈíÆ
                    if st.button("üìà Smart Report", key=f"smart_report_{file['id']}",
                                 help="Generate smart analysis report and charts", width='stretch'):
                        with st.spinner("Generating smart report..."):
                            result = storage_manager.generate_smart_report(file['id'])
                            if result["success"]:
                                st.session_state[f"show_report_{file['id']}"] = True
                                st.session_state[f"report_data_{file['id']}"] = result
                                st.success("Smart report generated successfully!")
                                st.rerun()
                            else:
                                st.error(f"Report generation failed: {result['error']}")





                with col2:
                    # ÁºìÂ≠òÊåâÈíÆ
                    if not file.get('is_cached', False):
                        if st.button("üíæ Cache", key=f"cache_{file['id']}", help="Cache to local", width='stretch'):
                            if storage_manager.cache_file(file['id']):
                                st.success("Cached successfully!")
                                st.rerun()
                            else:
                                st.error("Cache failed")
                    else:
                        st.success("Cached")

                    # ‰∏ãËΩΩÊåâÈíÆ
                    if st.button("üì• Download", key=f"download_btn_{file['id']}", help="Download file", width='stretch'):
                        file_data = storage_manager.preview_file(file['id'])
                        if file_data:
                            st.download_button(
                                "üì• Download File",
                                file_data,
                                file.get('filename', 'file'),
                                key=f"download_file_{file.get('id', 'unknown')}"
                            )
                        else:
                            st.error("File not found")

                # Analysis request
                user_question = st.text_area(
                    "üí¨ Ask anything about your data:",
                    height=100,
                    placeholder="Examples: 'Show me sales trends', 'Find correlations', 'Analyze customer demographics', 'Create visualizations', 'Tell me about this data'"
                )

                if st.button("üöÄ Generate Analysis", type="primary") and user_question:
                    with st.spinner("ü§î Analyzing your request..."):
                        # ‰ΩøÁî®pandas DataFrameÊ†ºÂºèËØªÂèñexcelÂíåcsvÊñá‰ª∂
                        result = storage_manager.generate_ai_report(file['id'], user_question)
                        if result["success"]:
                            st.success("Smart report generated successfully!")
                            #st.rerun()
                        else:
                            st.error(f"Report generation failed: {result['error']}")

                # Êñá‰ª∂Êìç‰ΩúËèúÂçï
                with st.popover("‚öôÔ∏è Actions", help="File operation menu"):
                    # ÈáçÂëΩÂêç
                    new_name = st.text_input("Rename", value=file.get('filename', ''),
                                             key=f"rename_input_{file.get('id', 'unknown')}")
                    if st.button("‚úÖ Confirm Rename", key=f"rename_confirm_{file['id']}"):
                        result = storage_manager.rename_file(file['id'], new_name)
                        if result["success"]:
                            st.success("Rename successful!")
                            st.rerun()
                        else:
                            st.error(f"Rename failed: {result['error']}")

                    st.markdown("---")

                    # ÁßªÂä®Êñá‰ª∂
                    st.markdown("**Move to Folder:**")
                    move_folders = storage_manager.get_folders()
                    move_options = ["Root Directory"] + [f["folder_name"] for f in move_folders]
                    target_move_folder = st.selectbox("Select Target Folder", move_options,
                                                      key=f"move_folder_{file['id']}")

                    if st.button("üìÅ Move File", key=f"move_file_{file['id']}"):
                        target_move_folder_id = None
                        if target_move_folder != "Root Directory":
                            for folder in move_folders:
                                if folder["folder_name"] == target_move_folder:
                                    target_move_folder_id = folder["id"]
                                    break

                        conn = sqlite3.connect(storage_manager.db_path)
                        cursor = conn.cursor()
                        cursor.execute('UPDATE files SET folder_id = ? WHERE id = ?',
                                       (target_move_folder_id, file['id']))
                        conn.commit()
                        conn.close()

                        st.success(f"File moved to {target_move_folder}!")
                        st.rerun()

                    st.markdown("---")

                    # Âà†Èô§
                    if st.button("üóëÔ∏è Delete File", key=f"delete_{file['id']}", help="Permanently delete file"):
                        if st.session_state.get(f"confirm_delete_{file['id']}", False):
                            result = storage_manager.delete_file(file['id'])
                            if result["success"]:
                                st.success("File deleted!")
                                st.rerun()
                            else:
                                st.error(f"Delete failed: {result['error']}")
                        else:
                            st.session_state[f"confirm_delete_{file['id']}"] = True
                            st.warning("‚ö†Ô∏è Click again to confirm deletion")

            with col_right:
                # È¢ÑËßàÂÜÖÂÆπÂå∫Âüü - ÊîæÂú®Âè≥‰æßÂàó
                if show_preview:
                    st.markdown("#### üìÑ File Preview")

                    file_data = storage_manager.preview_file(file['id'])
                    if file_data:
                        if file['file_type'] == 'image':
                            st.image(file_data, caption=file.get('filename', ''), width='stretch')
                        elif file['file_type'] == 'application' and str(file.get('filename', '')).endswith('.pdf'):
                            if PDF_AVAILABLE:
                                try:
                                    # ‰ΩøÁî®BytesIOÂåÖË£ÖÊï∞ÊçÆ
                                    import io

                                    pdf_stream = io.BytesIO(file_data)
                                    doc = fitz.open(stream=pdf_stream, filetype="pdf")

                                    if len(doc) > 0:
                                        page = doc[0]
                                        # ËÆæÁΩÆÂêàÈÄÇÁöÑÁº©ÊîæÊØî‰æã
                                        mat = fitz.Matrix(1.5, 1.5)  # 1.5ÂÄçÁº©Êîæ
                                        pix = page.get_pixmap(matrix=mat)
                                        img_data = pix.tobytes("png")
                                        st.image(img_data, caption=f"PDF Preview: {file.get('filename', '')} (Page 1)",
                                                 width='stretch')

                                        # ÊòæÁ§∫È°µÊï∞‰ø°ÊÅØ
                                        if len(doc) > 1:
                                            st.caption(f"PDF has {len(doc)} pages, showing page 1")
                                    else:
                                        st.warning("PDF file is empty or cannot be read")

                                    doc.close()
                                except Exception as e:
                                    st.error(f"PDF preview failed: {str(e)}")
                                    st.info("Try downloading the file to view content")
                                    st.download_button(
                                        "üì• Download PDF",
                                        file_data,
                                        file.get('filename', 'file.pdf'),
                                        key=f"preview_download_pdf_{file.get('id', 'unknown')}"
                                    )
                            else:
                                st.info("PDF preview requires PyMuPDF module")
                                st.info("Please run: pip install PyMuPDF")
                                st.download_button(
                                    "üì• Download PDF",
                                    file_data,
                                    file.get('filename', 'file.pdf'),
                                    key=f"preview_download_pdf_no_fitz_{file.get('id', 'unknown')}"
                                )
                        elif file['file_type'] == 'application' and str(file.get('filename', '')).endswith(
                                ('.xlsx', '.xls')):
                            try:
                                import pandas as pd
                                import io

                                df = pd.read_excel(io.BytesIO(file_data))
                                # Á°Æ‰øùDataFrame‰∏ç‰∏∫Á©∫
                                if not df.empty:
                                    # ÂÆâÂÖ®Âú∞ÊòæÁ§∫DataFrameÔºåÈÅøÂÖçnumpy.str_ÈîôËØØ
                                    try:
                                        st.dataframe(df.head(10), width='stretch')
                                        st.caption(f"Excel Preview: {file.get('filename', '')} (Showing first 10 rows)")
                                    except Exception as display_error:
                                        # Â¶ÇÊûúdataframeÊòæÁ§∫Â§±Ë¥•ÔºåÊòæÁ§∫Âü∫Êú¨‰ø°ÊÅØ
                                        st.write(f"Excel File: {file.get('filename', '')}")
                                        st.write(f"Rows: {len(df)}, Columns: {len(df.columns)}")
                                        st.write("Column names:", list(df.columns))
                                else:
                                    st.warning("Excel file is empty")
                            except Exception as e:
                                st.error(f"Excel preview failed: {str(e)}")
                                st.download_button(
                                    "üì• Download Excel",
                                    file_data,
                                    file.get('filename', 'file.xlsx'),
                                    key=f"preview_download_excel_{file.get('id', 'unknown')}"
                                )
                        elif file['file_type'] == 'text' or str(file.get('filename', '')).endswith('.txt'):
                            try:
                                text_content = file_data.decode('utf-8')
                                st.text_area("File Content", text_content[:1000], height=200,
                                             key=f"text_preview_{file.get('id', 'unknown')}")
                                if len(text_content) > 1000:
                                    st.caption(
                                        f"Text Preview: {file.get('filename', '')} (Showing first 1000 characters)")
                                else:
                                    st.caption(f"Text Preview: {file.get('filename', '')}")
                            except Exception as e:
                                st.error(f"Text preview failed: {str(e)}")
                                st.download_button(
                                    "üì• Download Text",
                                    file_data,
                                    file.get('filename', 'file.txt'),
                                    key=f"preview_download_txt_{file.get('id', 'unknown')}"
                                )
                        else:
                            st.info(f"Preview not supported for {file['file_type']} file type")
                            st.download_button(
                                "üì• Download File",
                                file_data,
                                file.get('filename', 'file'),
                                key=f"preview_download_other_{file.get('id', 'unknown')}"
                            )
                    else:
                        st.error("Unable to read file content")

            # AIÂàÜÊûêÁªìÊûúÊòæÁ§∫
            ai_analysis = storage_manager.get_ai_analysis(file['id'])
            if ai_analysis:
                st.markdown("---")
                st.markdown("#### ü§ñ AI Analysis Results")

                col1, col2 = st.columns([1, 1])

                with col1:
                    st.markdown(f"**Industry Category**: {ai_analysis['industry_category']}")
                    st.markdown(f"**Confidence**: {ai_analysis['confidence_score']:.2%}")
                    st.markdown(f"**Analysis Method**: {ai_analysis.get('method', 'Unknown')}")
                    st.markdown(f"**Analysis Time**: {ai_analysis['analysis_time']}")

                with col2:
                    if ai_analysis['key_phrases']:
                        st.markdown("**Key Phrases**:")
                        for phrase in ai_analysis['key_phrases'][:5]:
                            st.markdown(f"‚Ä¢ {phrase}")

                if ai_analysis['summary']:
                    st.markdown("**Document Summary**:")
                    st.info(ai_analysis['summary'])

                # Auto classify button: only show error when user clicks and action fails
                auto_clicked = st.button(
                    "üìÅ Auto Classify",
                    key=f"auto_classify_{file['id']}",
                    help="Move file to corresponding industry folder"
                )
                if auto_clicked:
                    if storage_manager.move_file_to_industry_folder(file['id'], ai_analysis['industry_category']):
                        st.success(f"File moved to {ai_analysis['industry_category']} folder!")
                        st.rerun()
                    else:
                        st.error("Classification failed")

            # Êô∫ËÉΩÊä•ÂëäÊòæÁ§∫
            if st.session_state.get(f"show_report_{file['id']}", False):
                report_data = st.session_state.get(f"report_data_{file['id']}")
                if report_data and report_data["success"]:
                    st.markdown("---")
                    st.markdown("#### üìà Smart Analysis Report")

                    # ÊòæÁ§∫Êä•ÂëäÂÜÖÂÆπ
                    st.markdown(report_data["report"])

                    # ÊòæÁ§∫ÂõæË°®
                    if report_data["charts"]:
                        st.markdown("#### üìä Data Visualization Charts")

                        for chart in report_data["charts"]:
                            st.markdown(f"**{chart['title']}**")

                            if chart['type'] == 'bar':
                                # Êü±Áä∂Âõæ
                                chart_data = pd.DataFrame({
                                    'Category': chart['data']['labels'],
                                    'Value': chart['data']['values']
                                })
                                st.bar_chart(chart_data.set_index('Category'))

                            elif chart['type'] == 'pie':
                                # È•ºÂõæ
                                pie_data = pd.DataFrame({
                                    'Category': chart['data']['labels'],
                                    'Value': chart['data']['values'],
                                    'Percentage': chart['data']['percentages']
                                })
                                st.dataframe(pie_data)

                            elif chart['type'] == 'line':
                                # ÊäòÁ∫øÂõæ
                                line_data = pd.DataFrame({
                                    'Category': chart['data']['labels'],
                                    'Value': chart['data']['values']
                                })
                                st.line_chart(line_data.set_index('Category'))

                            st.markdown("---")

                    # ÂÖ≥Èó≠Êä•ÂëäÊåâÈíÆ
                    if st.button("‚ùå Close Report", key=f"close_report_{file['id']}"):
                        st.session_state[f"show_report_{file['id']}"] = False
                        st.rerun()


else:
    # Á©∫Áä∂ÊÄÅ
    st.markdown("<div style='text-align: center; padding: 40px 0;'>", unsafe_allow_html=True)
    st.header("üìÅ No Files")
    st.subheader("Upload your first file to start using cloud storage")
    st.markdown("</div>", unsafe_allow_html=True)

    # ÂäüËÉΩËØ¥Êòé
    features = st.columns(3)
    with features[0]:
        st.info("""
        **üì§ File Upload**
        - Multiple formats support
        - Resume upload
        - Auto validation
        """)
    with features[1]:
        st.success("""
        **üëÅÔ∏è Online Preview**
        - Instant image preview
        - PDF document viewing
        - No download needed
        """)
    with features[2]:
        st.warning("""
        **üíæ Local Cache**
        - Offline access
        - Auto sync
        - Smart management
        """)

# È°µËÑö
st.markdown("---")
st.markdown("**Built by AfriCloud Team ‚ù§Ô∏è‚òÅÔ∏è **")